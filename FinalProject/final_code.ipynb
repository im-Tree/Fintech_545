{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy import optimize\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma, kv, logsumexp\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "from joblib import Parallel, delayed  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from typing import Dict, List, Callable, Any\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 & Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExPostAttribution:\n",
    "    def __init__(self, attribution, weights, factor_weights, resid_individual, resid_return, carino_k):\n",
    "        self.attribution = attribution\n",
    "        self.weights = weights\n",
    "        self.factor_weights = factor_weights\n",
    "        self.resid_individual = resid_individual\n",
    "        self.resid_return = resid_return\n",
    "        self.carino_k = carino_k\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.attribution)\n",
    "\n",
    "def expost_factor(w, up_returns, up_ff_data, betas):\n",
    "    \"\"\"\n",
    "    Compute the ex-post factor attribution for a portfolio\n",
    "    \n",
    "    Parameters:\n",
    "    w: initial weights vector (1D array)\n",
    "    up_returns: DataFrame of returns for stocks\n",
    "    up_ff_data: DataFrame of factor returns\n",
    "    betas: Factor exposures vector (1D array)\n",
    "    \"\"\"\n",
    "    _up_ff_data = up_ff_data.copy()\n",
    "    stocks = up_returns.columns.tolist()\n",
    "    factors = up_ff_data.columns.tolist()\n",
    "    \n",
    "    n = len(up_returns)\n",
    "    m = len(stocks)\n",
    "    \n",
    "    p_return = np.zeros(n)\n",
    "    resid_return = np.zeros(n)\n",
    "    weights = np.zeros((n, len(w)))\n",
    "    factor_weights = np.zeros((n, len(factors)))\n",
    "    last_w = w.copy()\n",
    "    \n",
    "    mat_returns = up_returns[stocks].values\n",
    "    ff_returns = up_ff_data[factors].values\n",
    "    \n",
    "    # Calculate residual individual returns (ensure correct broadcasting)\n",
    "    # Each stock's return minus its beta times the factor return\n",
    "    resid_individual = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            resid_individual[i, j] = mat_returns[i, j] - betas[j] * ff_returns[i, 0]\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Save current weights in matrix\n",
    "        weights[i, :] = last_w\n",
    "        \n",
    "        # Factor weight - for each factor, sum of beta * weight across stocks\n",
    "        for f in range(len(factors)):\n",
    "            factor_weights[i, f] = np.sum(betas * last_w)\n",
    "        \n",
    "        # Update weights by return\n",
    "        last_w = last_w * (1.0 + mat_returns[i, :])\n",
    "        \n",
    "        # Portfolio return is the sum of the updated weights\n",
    "        p_r = np.sum(last_w)\n",
    "        \n",
    "        # Normalize the weights back so sum = 1\n",
    "        last_w = last_w / p_r\n",
    "        \n",
    "        # Store the return\n",
    "        p_return[i] = p_r - 1\n",
    "        \n",
    "        # Residual\n",
    "        resid_return[i] = (p_r - 1) - np.dot(factor_weights[i, :], ff_returns[i, :])\n",
    "    \n",
    "    # Set the portfolio return in the update return DataFrame\n",
    "    _up_ff_data['Alpha'] = resid_return\n",
    "    _up_ff_data['Portfolio'] = p_return\n",
    "    \n",
    "    # Calculate the total return\n",
    "    total_ret = np.exp(np.sum(np.log(p_return + 1))) - 1\n",
    "    \n",
    "    # Calculate the Carino K\n",
    "    k = np.log(total_ret + 1) / total_ret if total_ret != 0 else 1.0\n",
    "    \n",
    "    # Carino k_t is the ratio scaled by 1/K\n",
    "    carino_k = np.zeros_like(p_return)\n",
    "    for i in range(len(p_return)):\n",
    "        if p_return[i] != 0:\n",
    "            carino_k[i] = np.log(1.0 + p_return[i]) / p_return[i] / k\n",
    "        else:\n",
    "            carino_k[i] = 1.0 / k\n",
    "    \n",
    "    # Calculate the return attribution\n",
    "    attrib = pd.DataFrame(ff_returns * factor_weights * carino_k.reshape(-1, 1), columns=factors)\n",
    "    attrib['Alpha'] = resid_return * carino_k\n",
    "    \n",
    "    # Update residual individual by weights\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            resid_individual[i, j] *= weights[i, j]\n",
    "    \n",
    "    # Set up a DataFrame for output\n",
    "    attribution = pd.DataFrame({'Value': ['TotalReturn', 'Return Attribution']})\n",
    "    \n",
    "    new_factors = factors + ['Alpha']\n",
    "    \n",
    "    # Loop over the factors\n",
    "    for s in new_factors + ['Portfolio']:\n",
    "        # Total stock return over the period\n",
    "        tr = np.exp(np.sum(np.log(_up_ff_data[s] + 1))) - 1\n",
    "        # Attribution Return (total portfolio return if we are updating the portfolio column)\n",
    "        atr = tr if s == 'Portfolio' else np.sum(attrib[s])\n",
    "        # Set the values\n",
    "        attribution[s] = [tr, atr]\n",
    "    \n",
    "    # Realized Volatility Attribution\n",
    "    \n",
    "    # Y is our stock returns scaled by their weight at each time\n",
    "    Y = np.hstack((ff_returns * factor_weights, resid_return.reshape(-1, 1)))\n",
    "    \n",
    "    # Set up X with the Portfolio Return\n",
    "    X = np.column_stack((np.ones(len(p_return)), p_return))\n",
    "    \n",
    "    # Calculate the Beta and discard the intercept\n",
    "    B = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    B = B[1, :]\n",
    "    \n",
    "    # Component SD is Beta times the standard deviation of the portfolio\n",
    "    cSD = B * np.std(p_return)\n",
    "    \n",
    "    # Check that the sum of component SD is equal to the portfolio SD\n",
    "    # sum(cSD) should approximately equal np.std(p_return)\n",
    "    \n",
    "    # Add the Vol attribution to the output\n",
    "    vol_attrib = pd.DataFrame({'Value': ['Vol Attribution']})\n",
    "    portfolio_vol = 0\n",
    "    for i, factor in enumerate(new_factors):\n",
    "        portfolio_vol += cSD[i]\n",
    "        vol_attrib[factor] = [cSD[i]]\n",
    "    vol_attrib['Portfolio'] = [portfolio_vol]\n",
    "    \n",
    "    attribution = pd.concat([attribution, vol_attrib], ignore_index=True)\n",
    "    \n",
    "    return ExPostAttribution(\n",
    "        attribution,\n",
    "        weights,\n",
    "        factor_weights,\n",
    "        resid_individual,\n",
    "        resid_return,\n",
    "        carino_k\n",
    "    )\n",
    "\n",
    "def return_calculate(prices, method=\"DISCRETE\", date_column=\"Date\"):\n",
    "    \"\"\"\n",
    "    Calculate returns from prices\n",
    "    \n",
    "    Parameters:\n",
    "    prices: DataFrame of prices\n",
    "    method: \"DISCRETE\" or \"LOG\"\n",
    "    date_column: name of the date column\n",
    "    \"\"\"\n",
    "    vars = prices.columns.tolist()\n",
    "    vars = [v for v in vars if v != date_column]\n",
    "    \n",
    "    if len(vars) == 0:\n",
    "        raise ValueError(f\"dateColumn: {date_column} not in DataFrame: {prices.columns}\")\n",
    "    \n",
    "    p = prices[vars].values\n",
    "    n = p.shape[0]\n",
    "    m = p.shape[1]\n",
    "    p2 = np.zeros((n-1, m))\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(m):\n",
    "            p2[i, j] = p[i+1, j] / p[i, j]\n",
    "    \n",
    "    if method.upper() == \"DISCRETE\":\n",
    "        p2 = p2 - 1.0\n",
    "    elif method.upper() == \"LOG\":\n",
    "        p2 = np.log(p2)\n",
    "    else:\n",
    "        raise ValueError(f\"method: {method} must be in (\\\"LOG\\\",\\\"DISCRETE\\\")\")\n",
    "    \n",
    "    dates = prices[date_column].iloc[1:n].reset_index(drop=True)\n",
    "    out = pd.DataFrame({date_column: dates})\n",
    "    \n",
    "    for i, var in enumerate(vars):\n",
    "        out[var] = p2[:, i]\n",
    "    \n",
    "    return out\n",
    "\n",
    "def OLS(X, Y):\n",
    "    \"\"\"\n",
    "    Ordinary Least Squares regression\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    X_with_constant = np.column_stack((np.ones(n), X))\n",
    "    b = np.linalg.inv(X_with_constant.T @ X_with_constant) @ (X_with_constant.T @ Y)\n",
    "    return b\n",
    "\n",
    "def run_attribution(realized_returns, realized_spy, last_date, start_prices, portfolio, betas, portfolio_type=\"Initial\"):\n",
    "    \"\"\"\n",
    "    Run the attribution analysis\n",
    "    \n",
    "    Parameters:\n",
    "    realized_returns: DataFrame of realized returns for stocks\n",
    "    realized_spy: DataFrame of realized returns for SPY\n",
    "    last_date: last date before the holding period\n",
    "    start_prices: DataFrame of prices at the start of the holding period\n",
    "    portfolio: DataFrame of portfolio holdings\n",
    "    betas: Array of betas for each stock in the portfolio\n",
    "    portfolio_type: String indicating the type of portfolio for reporting\n",
    "    \"\"\"\n",
    "    # Extract the stocks in order\n",
    "    stocks = portfolio['Symbol'].tolist()\n",
    "    \n",
    "    # Calculate total portfolio value and initial weights\n",
    "    holdings = portfolio['Holding'].values\n",
    "    start_price_values = start_prices.values[0]  # Get the values from the DataFrame\n",
    "    \n",
    "    t_value = np.sum(start_price_values * holdings)\n",
    "    w = (start_price_values * holdings) / t_value\n",
    "    \n",
    "    attrib = expost_factor(w, realized_returns, realized_spy, betas)\n",
    "    print(f\"\\n{portfolio_type} Total Portfolio Attribution\")\n",
    "    print(attrib.attribution)\n",
    "    \n",
    "    # Track attribution results for each portfolio\n",
    "    all_results = {\n",
    "        'Total': attrib.attribution\n",
    "    }\n",
    "    \n",
    "    portfolios = sorted(list(set(portfolio['Portfolio'])))\n",
    "    for p in portfolios:\n",
    "        # Filter stocks in this portfolio\n",
    "        stocks_mask = portfolio['Portfolio'] == p\n",
    "        p_stocks = portfolio.loc[stocks_mask, 'Symbol'].tolist()\n",
    "        \n",
    "        # Get stock returns and prices for this portfolio\n",
    "        stock_returns = realized_returns[p_stocks]\n",
    "        p_start_prices = start_prices[p_stocks].values[0]\n",
    "        \n",
    "        # Get holdings for these stocks\n",
    "        p_holdings = portfolio.loc[stocks_mask, 'Holding'].values\n",
    "        \n",
    "        # Calculate weights\n",
    "        p_t_value = np.sum(p_start_prices * p_holdings)\n",
    "        p_w = (p_start_prices * p_holdings) / p_t_value\n",
    "        \n",
    "        # Get betas for these stocks\n",
    "        p_betas = np.array([betas[stocks.index(s)] for s in p_stocks])\n",
    "        \n",
    "        # Run attribution analysis\n",
    "        p_attrib = expost_factor(p_w, stock_returns, realized_spy, p_betas)\n",
    "        print(f\"{portfolio_type} {p} Portfolio Attribution\")\n",
    "        print(p_attrib.attribution, '\\n')\n",
    "        \n",
    "        all_results[p] = p_attrib.attribution\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def calculate_expected_returns(betas, avg_mkt_return, avg_rf):\n",
    "    \"\"\"\n",
    "    Calculate expected returns using CAPM\n",
    "    \n",
    "    Parameters:\n",
    "    betas: Array of betas for each stock\n",
    "    avg_mkt_return: Average market return\n",
    "    avg_rf: Average risk-free rate\n",
    "    \n",
    "    Returns:\n",
    "    Array of expected returns for each stock\n",
    "    \"\"\"\n",
    "    return avg_rf + betas * (avg_mkt_return - avg_rf)\n",
    "\n",
    "def calculate_covariance_matrix(returns, betas, market_returns):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrix using single-factor model\n",
    "    \n",
    "    Parameters:\n",
    "    returns: DataFrame of stock returns\n",
    "    betas: Array of betas for each stock\n",
    "    market_returns: Series of market returns\n",
    "    \n",
    "    Returns:\n",
    "    Covariance matrix\n",
    "    \"\"\"\n",
    "    n = len(betas)\n",
    "    market_var = np.var(market_returns)\n",
    "    \n",
    "    # Calculate residual returns\n",
    "    resid = np.zeros((len(returns), n))\n",
    "    for i in range(n):\n",
    "        resid[:, i] = returns.iloc[:, i] - betas[i] * market_returns\n",
    "    \n",
    "    # Calculate residual variances\n",
    "    resid_var = np.var(resid, axis=0)\n",
    "    \n",
    "    # Initialize covariance matrix\n",
    "    cov_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # Fill the covariance matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                # Diagonal elements: total variance\n",
    "                cov_matrix[i, j] = betas[i]**2 * market_var + resid_var[i]\n",
    "            else:\n",
    "                # Off-diagonal elements: systematic component only\n",
    "                cov_matrix[i, j] = betas[i] * betas[j] * market_var\n",
    "    \n",
    "    return cov_matrix\n",
    "\n",
    "def optimize_sharpe_ratio(exp_returns, cov_matrix, rf_rate):\n",
    "    \"\"\"\n",
    "    Find the weights that maximize the Sharpe ratio\n",
    "    \n",
    "    Parameters:\n",
    "    exp_returns: Array of expected returns for each stock\n",
    "    cov_matrix: Covariance matrix of stock returns\n",
    "    rf_rate: Risk-free rate\n",
    "    \n",
    "    Returns:\n",
    "    Array of optimal weights\n",
    "    \"\"\"\n",
    "    n = len(exp_returns)\n",
    "    \n",
    "    def negative_sharpe(weights):\n",
    "        portfolio_return = np.sum(weights * exp_returns)\n",
    "        portfolio_stddev = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "        return -(portfolio_return - rf_rate) / portfolio_stddev\n",
    "    \n",
    "    # Constraint: sum of weights = 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "    \n",
    "    # Bounds: all weights between 0 and 1 (long-only)\n",
    "    bounds = tuple((0, 1) for _ in range(n))\n",
    "    \n",
    "    # Initial guess: equal weights\n",
    "    initial_weights = np.ones(n) / n\n",
    "    \n",
    "    # Run optimization\n",
    "    result = minimize(negative_sharpe, initial_weights, method='SLSQP', \n",
    "                       bounds=bounds, constraints=constraints, options={'disp': False})\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "def create_optimal_portfolios(portfolio, betas, all_returns, to_fit, avg_rf):\n",
    "    \"\"\"\n",
    "    Create optimal portfolios based on maximum Sharpe ratio\n",
    "    \n",
    "    Parameters:\n",
    "    portfolio: DataFrame of portfolio holdings\n",
    "    betas: Array of betas for each stock\n",
    "    all_returns: DataFrame of all returns\n",
    "    to_fit: DataFrame of returns used for fitting\n",
    "    avg_rf: Average risk-free rate\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame of optimal portfolio holdings\n",
    "    \"\"\"\n",
    "    # Create a copy of the portfolio DataFrame to modify\n",
    "    optimal_portfolio = portfolio.copy()\n",
    "    \n",
    "    # Calculate average market return\n",
    "    avg_mkt_return = to_fit['SPY'].mean()\n",
    "\n",
    "    # Get unique portfolios\n",
    "    portfolios = sorted(list(set(portfolio['Portfolio'])))\n",
    "    \n",
    "    for p in portfolios:\n",
    "        # Filter stocks in this portfolio\n",
    "        stocks_mask = portfolio['Portfolio'] == p\n",
    "        p_stocks = portfolio.loc[stocks_mask, 'Symbol'].tolist()\n",
    "        \n",
    "        # Get betas for these stocks\n",
    "        p_betas = np.array([betas[portfolio['Symbol'].tolist().index(s)] for s in p_stocks])\n",
    "        \n",
    "        # Calculate expected returns\n",
    "        exp_returns = calculate_expected_returns(p_betas, avg_mkt_return, avg_rf)\n",
    "        \n",
    "        # Calculate covariance matrix\n",
    "        p_returns = to_fit[p_stocks]\n",
    "        cov_matrix = calculate_covariance_matrix(p_returns, p_betas, to_fit['SPY'])\n",
    "        \n",
    "        # Find optimal weights\n",
    "        optimal_weights = optimize_sharpe_ratio(exp_returns, cov_matrix, avg_rf)\n",
    "        \n",
    "        # Calculate total value of this portfolio\n",
    "        p_holdings = portfolio.loc[stocks_mask, 'Holding'].values\n",
    "        p_prices = all_returns[all_returns['Date'] < datetime(2024, 1, 1)]['Date'].max()\n",
    "        \n",
    "        # Normalize weights to maintain the same total portfolio value\n",
    "        # We'll set the total value to 1000 shares for simplicity\n",
    "        total_shares = 1000\n",
    "        optimal_holdings = optimal_weights * total_shares\n",
    "        \n",
    "        # Update holdings in the optimal portfolio DataFrame\n",
    "        for i, stock in enumerate(p_stocks):\n",
    "            optimal_portfolio.loc[optimal_portfolio['Symbol'] == stock, 'Holding'] = optimal_holdings[i]\n",
    "    \n",
    "    return optimal_portfolio\n",
    "\n",
    "def analyze_results(initial_results, optimal_results):\n",
    "    \"\"\"\n",
    "    Analyze and compare the results of initial and optimal portfolios\n",
    "    \n",
    "    Parameters:\n",
    "    initial_results: Dictionary of attribution results for initial portfolios\n",
    "    optimal_results: Dictionary of attribution results for optimal portfolios\n",
    "    \"\"\"\n",
    "    print(\"\\n==== PERFORMANCE COMPARISON: INITIAL VS OPTIMAL PORTFOLIOS ====\")\n",
    "    \n",
    "    # Compare total portfolio return\n",
    "    initial_total_return = initial_results['Total'].loc[0, 'Portfolio']\n",
    "    optimal_total_return = optimal_results['Total'].loc[0, 'Portfolio']\n",
    "    \n",
    "    print(f\"Total Portfolio Return: Initial {initial_total_return:.4f} vs Optimal {optimal_total_return:.4f}\")\n",
    "    print(f\"Improvement: {optimal_total_return - initial_total_return:.4f} ({(optimal_total_return - initial_total_return) / abs(initial_total_return) * 100:.2f}%)\")\n",
    "    \n",
    "    # Compare systematic vs idiosyncratic contributions\n",
    "    print(\"\\nSystematic vs Idiosyncratic Attribution:\")\n",
    "    print(f\"{'Portfolio':<10} {'Initial Systematic':<20} {'Initial Idiosyncratic':<20} {'Optimal Systematic':<20} {'Optimal Idiosyncratic':<20}\")\n",
    "    \n",
    "    portfolios = ['Total'] + sorted(list(set(initial_results.keys()) - {'Total'}))\n",
    "    \n",
    "    for p in portfolios:\n",
    "        init_systematic = initial_results[p].loc[1, 'SPY']\n",
    "        init_idiosyncratic = initial_results[p].loc[1, 'Alpha']\n",
    "        opt_systematic = optimal_results[p].loc[1, 'SPY']\n",
    "        opt_idiosyncratic = optimal_results[p].loc[1, 'Alpha']\n",
    "        \n",
    "        print(f\"{p:<10} {init_systematic:<20.4f} {init_idiosyncratic:<20.4f} {opt_systematic:<20.4f} {opt_idiosyncratic:<20.4f}\")\n",
    "    \n",
    "    # Compare volatility attribution\n",
    "    print(\"\\nVolatility Attribution:\")\n",
    "    print(f\"{'Portfolio':<10} {'Initial Systematic':<20} {'Initial Idiosyncratic':<20} {'Optimal Systematic':<20} {'Optimal Idiosyncratic':<20}\")\n",
    "    \n",
    "    for p in portfolios:\n",
    "        init_systematic_vol = initial_results[p].loc[2, 'SPY']\n",
    "        init_idiosyncratic_vol = initial_results[p].loc[2, 'Alpha']\n",
    "        opt_systematic_vol = optimal_results[p].loc[2, 'SPY']\n",
    "        opt_idiosyncratic_vol = optimal_results[p].loc[2, 'Alpha']\n",
    "        \n",
    "        print(f\"{p:<10} {init_systematic_vol:<20.4f} {init_idiosyncratic_vol:<20.4f} {opt_systematic_vol:<20.4f} {opt_idiosyncratic_vol:<20.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== PART 1: ATTRIBUTION ANALYSIS WITH INITIAL PORTFOLIOS ====\n",
      "\n",
      "Initial Total Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.035969   0.204731\n",
      "1  Return Attribution  0.244039 -0.039309   0.204731\n",
      "2     Vol Attribution  0.007207 -0.000131   0.007076\n",
      "Initial A Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.095555   0.136642\n",
      "1  Return Attribution  0.242621 -0.105980   0.136642\n",
      "2     Vol Attribution  0.007056  0.000348   0.007404 \n",
      "\n",
      "Initial B Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.028626   0.203526\n",
      "1  Return Attribution  0.234259 -0.030733   0.203526\n",
      "2     Vol Attribution  0.006411  0.000442   0.006854 \n",
      "\n",
      "Initial C Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373  0.022337   0.281172\n",
      "1  Return Attribution  0.255627  0.025546   0.281172\n",
      "2     Vol Attribution  0.007230  0.000678   0.007908 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the Data\n",
    "portfolio = pd.read_csv(\"initial_portfolio.csv\")\n",
    "rf = pd.read_csv(\"rf.csv\")\n",
    "prices = pd.read_csv(\"DailyPrices.csv\")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "prices['Date'] = pd.to_datetime(prices['Date'])\n",
    "rf['Date'] = pd.to_datetime(rf['Date'])\n",
    "\n",
    "# Calculate returns\n",
    "all_returns = return_calculate(prices, method=\"DISCRETE\", date_column=\"Date\")\n",
    "all_returns = pd.merge(all_returns, rf, on='Date', how='left')\n",
    "\n",
    "stocks = portfolio['Symbol'].tolist()\n",
    "n_stocks = len(stocks)\n",
    "\n",
    "# Fit the CAPM Model\n",
    "betas = np.zeros(n_stocks)\n",
    "\n",
    "# Filter data to before end of 2023\n",
    "to_fit = all_returns[all_returns['Date'] < datetime(2023, 12, 31)]\n",
    "\n",
    "# Calculate average risk-free rate\n",
    "avg_rf = to_fit['rf'].mean()\n",
    "\n",
    "for i, s in enumerate(stocks):\n",
    "    betas[i] = OLS(to_fit['SPY'] - to_fit['rf'], to_fit[s] - to_fit['rf'])[1]\n",
    "\n",
    "capm_betas = pd.DataFrame({'Symbol': stocks, 'Beta': betas})\n",
    "# print(\"CAPM Betas:\")\n",
    "# print(capm_betas)\n",
    "\n",
    "\n",
    "# Get realized returns from 2024 onwards\n",
    "realized_returns = all_returns[all_returns['Date'] >= datetime(2024, 1, 1)][stocks]\n",
    "realized_spy = pd.DataFrame({'SPY': all_returns[all_returns['Date'] >= datetime(2024, 1, 1)]['SPY']})\n",
    "\n",
    "# Get prices at the end of 2023\n",
    "last_date = all_returns[all_returns['Date'] < datetime(2024, 1, 1)]['Date'].max()\n",
    "start_prices = prices[prices['Date'] == last_date][stocks]\n",
    "\n",
    "print(\"\\n==== PART 1: ATTRIBUTION ANALYSIS WITH INITIAL PORTFOLIOS ====\")\n",
    "# Run the attribution analysis for initial portfolios\n",
    "initial_results = run_attribution(realized_returns, realized_spy, last_date, start_prices, portfolio, betas, \"Initial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== PART 2: OPTIMAL MAXIMUM SHARPE RATIO PORTFOLIOS ====\n",
      "\n",
      "Optimal Total Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.029040   0.241423\n",
      "1  Return Attribution  0.273015 -0.031591   0.241423\n",
      "2     Vol Attribution  0.007677  0.000208   0.007886\n",
      "Optimal A Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.053660   0.224511\n",
      "1  Return Attribution  0.284686 -0.060175   0.224511\n",
      "2     Vol Attribution  0.007845  0.001252   0.009097 \n",
      "\n",
      "Optimal B Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.069802   0.186744\n",
      "1  Return Attribution  0.263700 -0.076955   0.186744\n",
      "2     Vol Attribution  0.007204  0.000182   0.007386 \n",
      "\n",
      "Optimal C Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373  0.011513   0.288082\n",
      "1  Return Attribution  0.274086  0.013996   0.288082\n",
      "2     Vol Attribution  0.006846  0.002063   0.008908 \n",
      "\n",
      "\n",
      "==== PERFORMANCE COMPARISON: INITIAL VS OPTIMAL PORTFOLIOS ====\n",
      "Total Portfolio Return: Initial 0.2047 vs Optimal 0.2414\n",
      "Improvement: 0.0367 (17.92%)\n",
      "\n",
      "Systematic vs Idiosyncratic Attribution:\n",
      "Portfolio  Initial Systematic   Initial Idiosyncratic Optimal Systematic   Optimal Idiosyncratic\n",
      "Total      0.2440               -0.0393              0.2730               -0.0316             \n",
      "A          0.2426               -0.1060              0.2847               -0.0602             \n",
      "B          0.2343               -0.0307              0.2637               -0.0770             \n",
      "C          0.2556               0.0255               0.2741               0.0140              \n",
      "\n",
      "Volatility Attribution:\n",
      "Portfolio  Initial Systematic   Initial Idiosyncratic Optimal Systematic   Optimal Idiosyncratic\n",
      "Total      0.0072               -0.0001              0.0077               0.0002              \n",
      "A          0.0071               0.0003               0.0078               0.0013              \n",
      "B          0.0064               0.0004               0.0072               0.0002              \n",
      "C          0.0072               0.0007               0.0068               0.0021              \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==== PART 2: OPTIMAL MAXIMUM SHARPE RATIO PORTFOLIOS ====\")\n",
    "# Create optimal portfolios\n",
    "optimal_portfolio = create_optimal_portfolios(portfolio, betas, all_returns, to_fit, avg_rf)\n",
    "\n",
    "# Display optimal weights\n",
    "# print(\"\\nOptimal Portfolio Weights:\")\n",
    "portfolios = sorted(list(set(optimal_portfolio['Portfolio'])))\n",
    "for p in portfolios:\n",
    "    p_stocks = optimal_portfolio[optimal_portfolio['Portfolio'] == p]\n",
    "    total_holding = p_stocks['Holding'].sum()\n",
    "    p_weights = p_stocks['Holding'] / total_holding\n",
    "    \n",
    "    # print(f\"\\nPortfolio {p} Optimal Weights:\")\n",
    "    # for i, (_, row) in enumerate(p_stocks.iterrows()):\n",
    "    #     print(f\"{row['Symbol']}: {p_weights.iloc[i]:.4f}\")\n",
    "\n",
    "# Run attribution analysis for optimal portfolios\n",
    "optimal_results = run_attribution(realized_returns, realized_spy, last_date, start_prices, optimal_portfolio, betas, \"Optimal\")\n",
    "\n",
    "# Analyze and compare results\n",
    "analyze_results(initial_results, optimal_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating risk metrics...\n",
      "Fitting distributions to each stock...\n",
      "Fitting distributions for SPY...\n",
      "Fitting distributions for AAPL...\n",
      "Fitting distributions for NVDA...\n",
      "Fitting distributions for MSFT...\n",
      "Fitting distributions for AMZN...\n",
      "Fitting distributions for META...\n",
      "Fitting distributions for GOOGL...\n",
      "Fitting distributions for AVGO...\n",
      "Fitting distributions for TSLA...\n",
      "Fitting distributions for GOOG...\n",
      "Fitting distributions for BRK-B...\n",
      "Fitting distributions for JPM...\n",
      "Fitting distributions for LLY...\n",
      "Fitting distributions for V...\n",
      "Fitting distributions for XOM...\n",
      "Fitting distributions for UNH...\n",
      "Fitting distributions for MA...\n",
      "Fitting distributions for COST...\n",
      "Fitting distributions for PG...\n",
      "Fitting distributions for WMT...\n",
      "Fitting distributions for HD...\n",
      "Fitting distributions for NFLX...\n",
      "Fitting distributions for JNJ...\n",
      "Fitting distributions for ABBV...\n",
      "Fitting distributions for CRM...\n",
      "Fitting distributions for BAC...\n",
      "Fitting distributions for ORCL...\n",
      "Fitting distributions for MRK...\n",
      "Fitting distributions for CVX...\n",
      "Fitting distributions for KO...\n",
      "Fitting distributions for CSCO...\n",
      "Fitting distributions for WFC...\n",
      "Fitting distributions for ACN...\n",
      "Fitting distributions for NOW...\n",
      "Fitting distributions for MCD...\n",
      "Fitting distributions for PEP...\n",
      "Fitting distributions for IBM...\n",
      "Fitting distributions for DIS...\n",
      "Fitting distributions for TMO...\n",
      "Fitting distributions for LIN...\n",
      "Fitting distributions for ABT...\n",
      "Fitting distributions for AMD...\n",
      "Fitting distributions for ADBE...\n",
      "Fitting distributions for PM...\n",
      "Fitting distributions for ISRG...\n",
      "Fitting distributions for GE...\n",
      "Fitting distributions for GS...\n",
      "Fitting distributions for INTU...\n",
      "Fitting distributions for CAT...\n",
      "Fitting distributions for QCOM...\n",
      "Fitting distributions for TXN...\n",
      "Fitting distributions for VZ...\n",
      "Fitting distributions for AXP...\n",
      "Fitting distributions for T...\n",
      "Fitting distributions for BKNG...\n",
      "Fitting distributions for SPGI...\n",
      "Fitting distributions for MS...\n",
      "Fitting distributions for RTX...\n",
      "Fitting distributions for PLTR...\n",
      "Fitting distributions for PFE...\n",
      "Fitting distributions for BLK...\n",
      "Fitting distributions for DHR...\n",
      "Fitting distributions for NEE...\n",
      "Fitting distributions for HON...\n",
      "Fitting distributions for CMCSA...\n",
      "Fitting distributions for PGR...\n",
      "Fitting distributions for LOW...\n",
      "Fitting distributions for AMGN...\n",
      "Fitting distributions for UNP...\n",
      "Fitting distributions for TJX...\n",
      "Fitting distributions for AMAT...\n",
      "Fitting distributions for UBER...\n",
      "Fitting distributions for C...\n",
      "Fitting distributions for BSX...\n",
      "Fitting distributions for ETN...\n",
      "Fitting distributions for COP...\n",
      "Fitting distributions for BA...\n",
      "Fitting distributions for BX...\n",
      "Fitting distributions for SYK...\n",
      "Fitting distributions for PANW...\n",
      "Fitting distributions for ADP...\n",
      "Fitting distributions for FI...\n",
      "Fitting distributions for ANET...\n",
      "Fitting distributions for GILD...\n",
      "Fitting distributions for BMY...\n",
      "Fitting distributions for SCHW...\n",
      "Fitting distributions for TMUS...\n",
      "Fitting distributions for DE...\n",
      "Fitting distributions for ADI...\n",
      "Fitting distributions for VRTX...\n",
      "Fitting distributions for SBUX...\n",
      "Fitting distributions for MMC...\n",
      "Fitting distributions for MDT...\n",
      "Fitting distributions for CB...\n",
      "Fitting distributions for LMT...\n",
      "Fitting distributions for KKR...\n",
      "Fitting distributions for MU...\n",
      "Fitting distributions for PLD...\n",
      "Fitting distributions for LRCX...\n",
      "Fitting distributions for EQIX...\n",
      "\n",
      "Calculating VaR and ES for each portfolio...\n",
      "Processing portfolio: A\n",
      "  Simulating returns for portfolio A...\n",
      "Processing portfolio: B\n",
      "  Simulating returns for portfolio B...\n",
      "Processing portfolio: C\n",
      "  Simulating returns for portfolio C...\n",
      "Processing portfolio: Total\n",
      "  Simulating returns for portfolio Total...\n",
      "\n",
      "Best Fit Distribution for Each Stock (using AICC criterion):\n",
      "--------------------------------------------------------------------------------\n",
      "Symbol: SPY\n",
      "  Best Fit Model: Normal\n",
      "  Parameters: {'mu': 0, 'sigma': 0.00824684201271041}\n",
      "  AICC: -1681.7190\n",
      "\n",
      "Symbol: AAPL\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01530745862896632, 'nu': 4.9860445001663125, 'p': 1.9249622298382667}\n",
      "  AICC: -1476.4741\n",
      "\n",
      "Symbol: NVDA\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.03274502032363604, 'nu': 1.2114900154735568, 'p': 2.9674313003029575}\n",
      "  AICC: -1087.0949\n",
      "\n",
      "Symbol: MSFT\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01901641997681056, 'nu': 4.989272373110831, 'p': 1.8728705320147596}\n",
      "  AICC: -1360.9526\n",
      "\n",
      "Symbol: AMZN\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.023851332848633538, 'nu': 4.972577902767439, 'p': 1.794573879866977}\n",
      "  AICC: -1231.2825\n",
      "\n",
      "Symbol: META\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.023643731731089267, 'nu': 0.607444047506583, 'p': 4.6394759804945815}\n",
      "  AICC: -1237.9332\n",
      "\n",
      "Symbol: GOOGL\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.020564851962757105, 'nu': 1.4734632651309634, 'p': 2.4361636871764354}\n",
      "  AICC: -1288.8331\n",
      "\n",
      "Symbol: AVGO\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.02091977689411296, 'nu': 4.949552718154032, 'p': 1.6502428467230452}\n",
      "  AICC: -1262.3853\n",
      "\n",
      "Symbol: TSLA\n",
      "  Best Fit Model: NIG\n",
      "  Parameters: {'alpha': 72.90237910449495, 'beta': -817.6027543853693, 'mu': 0, 'delta': 0.0010000000001788578}\n",
      "  AICC: -inf\n",
      "\n",
      "Symbol: GOOG\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.021029981539260164, 'nu': 1.3708997608006492, 'p': 2.568314437358814}\n",
      "  AICC: -1283.5285\n",
      "\n",
      "Symbol: BRK-B\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.010033464951908305, 'nu': 4.984004261195996, 'p': 1.7983532267373108}\n",
      "  AICC: -1665.2807\n",
      "\n",
      "Symbol: JPM\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011876176351860397, 'nu': 4.940174324198197, 'p': 1.4548318777773064}\n",
      "  AICC: -1490.4601\n",
      "\n",
      "Symbol: LLY\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01535021628365197, 'nu': 2.227152151360406, 'p': 1.7144754431900742}\n",
      "  AICC: -1359.8393\n",
      "\n",
      "Symbol: V\n",
      "  Best Fit Model: Normal\n",
      "  Parameters: {'mu': 0, 'sigma': 0.009816409746842631}\n",
      "  AICC: -1594.9549\n",
      "\n",
      "Symbol: XOM\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.019076912895835966, 'nu': 4.991105508352455, 'p': 1.8989892708296672}\n",
      "  AICC: -1363.8752\n",
      "\n",
      "Symbol: UNH\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01187162582274109, 'nu': 4.933968407769765, 'p': 1.463216695107931}\n",
      "  AICC: -1490.9152\n",
      "\n",
      "Symbol: MA\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.012272343482788946, 'nu': 4.971589224459633, 'p': 1.7763735885158431}\n",
      "  AICC: -1559.3637\n",
      "\n",
      "Symbol: COST\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011794727289863667, 'nu': 4.951873161204252, 'p': 1.530309223965936}\n",
      "  AICC: -1519.4953\n",
      "\n",
      "Symbol: PG\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.010313461593275343, 'nu': 4.9733438320516115, 'p': 1.6767427413096743}\n",
      "  AICC: -1625.3615\n",
      "\n",
      "Symbol: WMT\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011111751744038282, 'nu': 4.99999868031108, 'p': 1.999998106824273}\n",
      "  AICC: -1640.3191\n",
      "\n",
      "Symbol: HD\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013744070033406093, 'nu': 4.9580442690267255, 'p': 1.5742508270742055}\n",
      "  AICC: -1455.3208\n",
      "\n",
      "Symbol: NFLX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.020269884694131192, 'nu': 4.923615347801984, 'p': 1.4158652628549615}\n",
      "  AICC: -1210.3934\n",
      "\n",
      "Symbol: JNJ\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.009140474945061466, 'nu': 4.930013691682994, 'p': 1.4231883760339727}\n",
      "  AICC: -1610.1066\n",
      "\n",
      "Symbol: ABBV\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011634518711006231, 'nu': 4.940273743214992, 'p': 1.5195433022943265}\n",
      "  AICC: -1520.4006\n",
      "\n",
      "Symbol: CRM\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01911000109930598, 'nu': 4.947117564822764, 'p': 1.6347426370904161}\n",
      "  AICC: -1305.4345\n",
      "\n",
      "Symbol: BAC\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.017157616091049672, 'nu': 4.963516567037304, 'p': 1.5487868559744875}\n",
      "  AICC: -1338.6324\n",
      "\n",
      "Symbol: ORCL\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01544051739836678, 'nu': 1.5029790482856384, 'p': 2.035532722320668}\n",
      "  AICC: -1368.0558\n",
      "\n",
      "Symbol: MRK\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.014485420508891263, 'nu': 4.992608012844015, 'p': 1.8993244689390565}\n",
      "  AICC: -1501.2879\n",
      "\n",
      "Symbol: CVX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.015139415756760345, 'nu': 4.962864602870602, 'p': 1.6161499082056352}\n",
      "  AICC: -1417.8782\n",
      "\n",
      "Symbol: KO\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.009242225517366367, 'nu': 4.962138509385358, 'p': 1.7301428878853888}\n",
      "  AICC: -1688.7392\n",
      "\n",
      "Symbol: CSCO\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011772223634838585, 'nu': 4.928682350896146, 'p': 1.5598510614003858}\n",
      "  AICC: -1522.3536\n",
      "\n",
      "Symbol: WFC\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01888456708847547, 'nu': 4.969505745539369, 'p': 1.6640400206346888}\n",
      "  AICC: -1320.1643\n",
      "\n",
      "Symbol: ACN\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.016532246797346137, 'nu': 2.838505801097883, 'p': 2.157493880558818}\n",
      "  AICC: -1436.6996\n",
      "\n",
      "Symbol: NOW\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.018192607714991683, 'nu': 7.217673937433716, 'p': 1.324293738164174}\n",
      "  AICC: -1258.7324\n",
      "\n",
      "Symbol: MCD\n",
      "  Best Fit Model: Normal\n",
      "  Parameters: {'mu': 0, 'sigma': 0.008798208000282446}\n",
      "  AICC: -1649.4896\n",
      "\n",
      "Symbol: PEP\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.010295886920931764, 'nu': 4.968927652661676, 'p': 1.6848917904050007}\n",
      "  AICC: -1627.6912\n",
      "\n",
      "Symbol: IBM\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01091877104553709, 'nu': 1.9385882021345973, 'p': 2.2070584921854546}\n",
      "  AICC: -1609.9793\n",
      "\n",
      "Symbol: DIS\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.017425226677123037, 'nu': 4.961864674134142, 'p': 1.6282555804295176}\n",
      "  AICC: -1351.0609\n",
      "\n",
      "Symbol: TMO\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.015828689634605153, 'nu': 4.974860023920766, 'p': 1.69541544215489}\n",
      "  AICC: -1415.6707\n",
      "\n",
      "Symbol: LIN\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011273959611947082, 'nu': 4.949424075569333, 'p': 1.4196717068240607}\n",
      "  AICC: -1505.5802\n",
      "\n",
      "Symbol: ABT\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.014816073140395623, 'nu': 4.999997035268142, 'p': 1.9999961600102405}\n",
      "  AICC: -1498.2057\n",
      "\n",
      "Symbol: AMD\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.03132331586721223, 'nu': 4.961906755382651, 'p': 1.6392931679933045}\n",
      "  AICC: -1061.4769\n",
      "\n",
      "Symbol: ADBE\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.02246461244404338, 'nu': 4.97477794303636, 'p': 1.7229232157403065}\n",
      "  AICC: -1247.7560\n",
      "\n",
      "Symbol: PM\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.012536931729873864, 'nu': 4.991815815704661, 'p': 1.8808581408606588}\n",
      "  AICC: -1570.1167\n",
      "\n",
      "Symbol: ISRG\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.017958932344902562, 'nu': 4.95441130168673, 'p': 1.5359841115515347}\n",
      "  AICC: -1312.1888\n",
      "\n",
      "Symbol: GE\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.018624347816777513, 'nu': 4.985192004568577, 'p': 1.93255941259095}\n",
      "  AICC: -1379.9867\n",
      "\n",
      "Symbol: GS\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.016747325655170422, 'nu': 4.972816964054447, 'p': 1.6940138454281584}\n",
      "  AICC: -1387.4702\n",
      "\n",
      "Symbol: INTU\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.020132672370175953, 'nu': 4.973093064674551, 'p': 1.6720148350271733}\n",
      "  AICC: -1291.2112\n",
      "\n",
      "Symbol: CAT\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.018594120063627165, 'nu': 4.946601300962683, 'p': 1.6562857622431986}\n",
      "  AICC: -1321.2942\n",
      "\n",
      "Symbol: QCOM\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.022373958509603078, 'nu': 2.063813591285017, 'p': 2.200339165977659}\n",
      "  AICC: -1259.4726\n",
      "\n",
      "Symbol: TXN\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01917024363471227, 'nu': 4.997030219354829, 'p': 2.0206368906931513}\n",
      "  AICC: -1380.4237\n",
      "\n",
      "Symbol: VZ\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01309637603536403, 'nu': 1.3704066133081347, 'p': 2.209696509962532}\n",
      "  AICC: -1465.9744\n",
      "\n",
      "Symbol: AXP\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.016821849703462878, 'nu': 3.282711434796349, 'p': 1.7509800701881884}\n",
      "  AICC: -1367.2701\n",
      "\n",
      "Symbol: T\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013066832029851188, 'nu': 0.20738426479640465, 'p': 9.0365270559231}\n",
      "  AICC: -1411.4737\n",
      "\n",
      "Symbol: BKNG\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.019539207111875567, 'nu': 4.999997921210902, 'p': 1.9999983032434012}\n",
      "  AICC: -1366.6300\n",
      "\n",
      "Symbol: SPGI\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013650859123692153, 'nu': 4.945754323802616, 'p': 1.5752774983854374}\n",
      "  AICC: -1456.3638\n",
      "\n",
      "Symbol: MS\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01644873824031853, 'nu': 4.95536894369843, 'p': 1.561595874882423}\n",
      "  AICC: -1362.2622\n",
      "\n",
      "Symbol: RTX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011318065093309161, 'nu': 4.906343600272421, 'p': 1.3137516460825136}\n",
      "  AICC: -1460.5491\n",
      "\n",
      "Symbol: PLTR\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.034509519752801615, 'nu': 4.925405518625597, 'p': 1.294052589254495}\n",
      "  AICC: -900.5627\n",
      "\n",
      "Symbol: PFE\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.014414332056879588, 'nu': 4.953327771903989, 'p': 1.5501179827756355}\n",
      "  AICC: -1423.8468\n",
      "\n",
      "Symbol: BLK\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.016863769603420797, 'nu': 4.989118064483039, 'p': 1.8898527137172279}\n",
      "  AICC: -1423.5777\n",
      "\n",
      "Symbol: DHR\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.017071710002605992, 'nu': 4.965945392122249, 'p': 1.7806750100816826}\n",
      "  AICC: -1393.1993\n",
      "\n",
      "Symbol: NEE\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.014593078351971173, 'nu': 4.922184119908457, 'p': 1.3893933510072063}\n",
      "  AICC: -1360.3965\n",
      "\n",
      "Symbol: HON\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013483545096325744, 'nu': 1.8734324841025063, 'p': 2.3906127900434266}\n",
      "  AICC: -1526.6173\n",
      "\n",
      "Symbol: CMCSA\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.015837094216386655, 'nu': 0.8104068974650752, 'p': 3.728882483511914}\n",
      "  AICC: -1439.8832\n",
      "\n",
      "Symbol: PGR\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013735565299783804, 'nu': 0.29007695402087824, 'p': 6.417165902811609}\n",
      "  AICC: -1389.8301\n",
      "\n",
      "Symbol: LOW\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.014246756568137847, 'nu': 4.960604540103765, 'p': 1.4588710702689207}\n",
      "  AICC: -1405.2986\n",
      "\n",
      "Symbol: AMGN\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.015048438951674908, 'nu': 4.981671008193113, 'p': 1.7710944936469435}\n",
      "  AICC: -1457.8058\n",
      "\n",
      "Symbol: UNP\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013412110911056385, 'nu': 4.921233342971223, 'p': 1.5251697140354872}\n",
      "  AICC: -1447.6536\n",
      "\n",
      "Symbol: TJX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.012735955894125357, 'nu': 4.999999434718418, 'p': 2.000003111850278}\n",
      "  AICC: -1581.9702\n",
      "\n",
      "Symbol: AMAT\n",
      "  Best Fit Model: Normal\n",
      "  Parameters: {'mu': 0, 'sigma': 0.02135165156587088}\n",
      "  AICC: -1207.9723\n",
      "\n",
      "Symbol: UBER\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.028980656611102284, 'nu': 4.997334126091681, 'p': 2.0527949390220934}\n",
      "  AICC: -1178.9585\n",
      "\n",
      "Symbol: C\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.015527272585234826, 'nu': 4.95476453468605, 'p': 1.4925928342501464}\n",
      "  AICC: -1371.6476\n",
      "\n",
      "Symbol: BSX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011369889694275489, 'nu': 4.941030229484167, 'p': 1.4262662009237714}\n",
      "  AICC: -1503.5143\n",
      "\n",
      "Symbol: ETN\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.016363679689550614, 'nu': 4.957155557028648, 'p': 1.5214398714984538}\n",
      "  AICC: -1353.1781\n",
      "\n",
      "Symbol: COP\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.02055178644897278, 'nu': 4.972140759912895, 'p': 1.8015233519736658}\n",
      "  AICC: -1306.2321\n",
      "\n",
      "Symbol: BA\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.017462275137320998, 'nu': 4.962447061308917, 'p': 1.5721644663493042}\n",
      "  AICC: -1336.3281\n",
      "\n",
      "Symbol: BX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.0239188797371523, 'nu': 6.7918686098818295, 'p': 1.5857368241619652}\n",
      "  AICC: -1201.8200\n",
      "\n",
      "Symbol: SYK\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.010407966645218819, 'nu': 4.923517680609638, 'p': 1.202916017635911}\n",
      "  AICC: -1454.2866\n",
      "\n",
      "Symbol: PANW\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.019730312568587774, 'nu': 4.924228164813597, 'p': 1.3529559835881995}\n",
      "  AICC: -1201.2220\n",
      "\n",
      "Symbol: ADP\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.010847013173949016, 'nu': 4.9255234082358035, 'p': 1.3650757781534222}\n",
      "  AICC: -1503.9405\n",
      "\n",
      "Symbol: FI\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011956723096751994, 'nu': 4.9226685972014135, 'p': 1.491296128970269}\n",
      "  AICC: -1494.9531\n",
      "\n",
      "Symbol: ANET\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.022338137140195186, 'nu': 1.2134865424417638, 'p': 2.157578484187757}\n",
      "  AICC: -1166.0876\n",
      "\n",
      "Symbol: GILD\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.015365048516505626, 'nu': 4.994693615386684, 'p': 1.852410352397351}\n",
      "  AICC: -1464.5674\n",
      "\n",
      "Symbol: BMY\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01240457605279423, 'nu': 4.956861380698167, 'p': 1.586907149365867}\n",
      "  AICC: -1508.8488\n",
      "\n",
      "Symbol: SCHW\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.019551441884868848, 'nu': 4.915817351600227, 'p': 1.253610554156742}\n",
      "  AICC: -1163.1486\n",
      "\n",
      "Symbol: TMUS\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013328920194718203, 'nu': 4.97420508494574, 'p': 1.7403033227932971}\n",
      "  AICC: -1510.8669\n",
      "\n",
      "Symbol: DE\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.019360325153597625, 'nu': 4.969054821781384, 'p': 1.773542358608103}\n",
      "  AICC: -1330.4073\n",
      "\n",
      "Symbol: ADI\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.018776983093946598, 'nu': 4.973905135777706, 'p': 1.7806806097308863}\n",
      "  AICC: -1348.4940\n",
      "\n",
      "Symbol: VRTX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013648261085663272, 'nu': 4.921940249890983, 'p': 1.4788180372270843}\n",
      "  AICC: -1427.0065\n",
      "\n",
      "Symbol: SBUX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.013164706827808865, 'nu': 4.924787715394479, 'p': 1.5761847524894879}\n",
      "  AICC: -1471.0403\n",
      "\n",
      "Symbol: MMC\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.011417230173547396, 'nu': 4.964482693885645, 'p': 1.6788426033326658}\n",
      "  AICC: -1574.1838\n",
      "\n",
      "Symbol: MDT\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01403707254908002, 'nu': 4.967753706732421, 'p': 1.5873973278059659}\n",
      "  AICC: -1449.3074\n",
      "\n",
      "Symbol: CB\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.014109677016829095, 'nu': 4.972511433827679, 'p': 1.6997130284154025}\n",
      "  AICC: -1473.9930\n",
      "\n",
      "Symbol: LMT\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.009852892117616726, 'nu': 4.9264616847056875, 'p': 1.4699996672923188}\n",
      "  AICC: -1586.0828\n",
      "\n",
      "Symbol: KKR\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.023362259363535108, 'nu': 4.986003283057382, 'p': 1.7991489156921396}\n",
      "  AICC: -1245.0833\n",
      "\n",
      "Symbol: MU\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.024333811111965864, 'nu': 4.97302756567917, 'p': 1.6194750216934821}\n",
      "  AICC: -1184.2358\n",
      "\n",
      "Symbol: PLD\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.019701811049126196, 'nu': 4.9815197172013885, 'p': 1.848394050141793}\n",
      "  AICC: -1337.5717\n",
      "\n",
      "Symbol: LRCX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.02523699313322797, 'nu': 4.975225479694659, 'p': 1.6820902650243292}\n",
      "  AICC: -1181.0339\n",
      "\n",
      "Symbol: EQIX\n",
      "  Best Fit Model: Generalized_T\n",
      "  Parameters: {'loc': 0, 'scale': 0.01653053737059685, 'nu': 4.973599712905184, 'p': 1.6480093085917829}\n",
      "  AICC: -1383.9593\n",
      "\n",
      "\n",
      "VaR and ES Results (1-day, 95% confidence level):\n",
      "--------------------------------------------------------------------------------\n",
      "Portfolio: A\n",
      "  Using Fitted Distributions with Gaussian Copula:\n",
      "    VaR: 0.013740\n",
      "    ES: 0.018105\n",
      "  Using Multivariate Normal:\n",
      "    VaR: 0.014216\n",
      "    ES: 0.017934\n",
      "\n",
      "Portfolio: B\n",
      "  Using Fitted Distributions with Gaussian Copula:\n",
      "    VaR: 0.012465\n",
      "    ES: 0.016327\n",
      "  Using Multivariate Normal:\n",
      "    VaR: 0.013227\n",
      "    ES: 0.016524\n",
      "\n",
      "Portfolio: C\n",
      "  Using Fitted Distributions with Gaussian Copula:\n",
      "    VaR: 0.012835\n",
      "    ES: 0.016619\n",
      "  Using Multivariate Normal:\n",
      "    VaR: 0.013769\n",
      "    ES: 0.017249\n",
      "\n",
      "Portfolio: Total\n",
      "  Using Fitted Distributions with Gaussian Copula:\n",
      "    VaR: 0.012663\n",
      "    ES: 0.016465\n",
      "  Using Multivariate Normal:\n",
      "    VaR: 0.013169\n",
      "    ES: 0.016700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "def load_data():\n",
    "    # Load stock prices\n",
    "    prices_df = pd.read_csv('DailyPrices.csv')\n",
    "    prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "    prices_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Load portfolio holdings\n",
    "    portfolio_df = pd.read_csv('initial_portfolio.csv')\n",
    "    \n",
    "    return prices_df, portfolio_df\n",
    "\n",
    "# Split data into pre-holding and holding periods\n",
    "def split_data(prices_df):\n",
    "    # Split data at 2024-01-01\n",
    "    pre_holding = prices_df[prices_df.index < '2024-01-01']\n",
    "    holding = prices_df[prices_df.index >= '2024-01-01']\n",
    "    \n",
    "    return pre_holding, holding\n",
    "\n",
    "# Calculate portfolio weights\n",
    "def calculate_weights(prices_df, portfolio_df):\n",
    "    # Get the last trading day of 2023\n",
    "    last_day_2023 = prices_df[prices_df.index < '2024-01-01'].index.max()\n",
    "    last_prices = prices_df.loc[last_day_2023]\n",
    "    \n",
    "    # Dictionary to store portfolio weights\n",
    "    portfolio_weights = {}\n",
    "    \n",
    "    # Calculate weights for each portfolio\n",
    "    for portfolio in portfolio_df['Portfolio'].unique():\n",
    "        portfolio_holdings = portfolio_df[portfolio_df['Portfolio'] == portfolio]\n",
    "        \n",
    "        # Calculate the total value of the portfolio\n",
    "        portfolio_values = {}\n",
    "        total_value = 0\n",
    "        \n",
    "        for _, row in portfolio_holdings.iterrows():\n",
    "            symbol = row['Symbol']\n",
    "            holding = row['Holding']\n",
    "            \n",
    "            # Skip if the symbol is not in the prices data\n",
    "            if symbol not in last_prices:\n",
    "                continue\n",
    "                \n",
    "            value = last_prices[symbol] * holding\n",
    "            portfolio_values[symbol] = value\n",
    "            total_value += value\n",
    "        \n",
    "        # Calculate weights\n",
    "        weights = {symbol: value / total_value for symbol, value in portfolio_values.items()}\n",
    "        portfolio_weights[portfolio] = weights\n",
    "        \n",
    "    # Calculate total weights across all portfolios\n",
    "    total_value = 0\n",
    "    portfolio_values = {}\n",
    "    for _, row in portfolio_df.iterrows():\n",
    "        symbol = row['Symbol']\n",
    "        holding = row['Holding']\n",
    "        \n",
    "        # Skip if the symbol is not in the prices data\n",
    "        if symbol not in last_prices:\n",
    "            continue\n",
    "            \n",
    "        value = last_prices[symbol] * holding\n",
    "        if symbol in portfolio_values:\n",
    "            portfolio_values[symbol] += value\n",
    "        else:\n",
    "            portfolio_values[symbol] = value\n",
    "        total_value += value\n",
    "    \n",
    "    # Calculate weights\n",
    "    weights = {symbol: value / total_value for symbol, value in portfolio_values.items()}\n",
    "    portfolio_weights['Total'] = weights\n",
    "    \n",
    "    return portfolio_weights, last_day_2023\n",
    "\n",
    "# Implementation of Higham's nearest positive definite matrix algorithm\n",
    "def nearest_pd(A):\n",
    "    \"\"\"Find the nearest positive-definite matrix to input A.\"\"\"\n",
    "    B = (A + A.T) / 2\n",
    "    _, s, V = np.linalg.svd(B)\n",
    "    \n",
    "    H = np.dot(V.T, np.dot(np.diag(s), V))\n",
    "    A2 = (B + H) / 2\n",
    "    A3 = (A2 + A2.T) / 2\n",
    "    \n",
    "    if is_pd(A3):\n",
    "        return A3\n",
    "    \n",
    "    spacing = np.spacing(np.linalg.norm(A))\n",
    "    I = np.eye(A.shape[0])\n",
    "    k = 1\n",
    "    while not is_pd(A3):\n",
    "        mineig = np.min(np.real(np.linalg.eigvals(A3)))\n",
    "        A3 += I * (-mineig * k**2 + spacing)\n",
    "        k += 1\n",
    "    \n",
    "    return A3\n",
    "\n",
    "def is_pd(A):\n",
    "    \"\"\"Returns True if A is positive definite.\"\"\"\n",
    "    try:\n",
    "        np.linalg.cholesky(A)\n",
    "        return True\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False\n",
    "\n",
    "# Implementation of different distributions\n",
    "class DistributionFitter:\n",
    "    def __init__(self):\n",
    "        self.distributions = {\n",
    "            'Normal': self.fit_normal,\n",
    "            'Generalized_T': self.fit_generalized_t,\n",
    "            'NIG': self.fit_nig,\n",
    "            'Skew_Normal': self.fit_skew_normal\n",
    "        }\n",
    "        self.fallback_flags = {}  # To track which distributions used fallback\n",
    "        \n",
    "    def fit_normal(self, data):\n",
    "        # Fit normal with mean constrained to zero\n",
    "        sigma = np.std(data, ddof=1)  # Unbiased estimation with ddof=1\n",
    "        mu = 0  # Fixed at zero as per requirement\n",
    "        \n",
    "        n = len(data)\n",
    "        k = 1  # Only one parameter (sigma) since mu is fixed at 0\n",
    "        loglik = np.sum(stats.norm.logpdf(data, mu, sigma))\n",
    "        \n",
    "        # Calculate AICC: AIC + 2k(k+1)/(n-k-1)\n",
    "        aic = 2 * k - 2 * loglik\n",
    "        aicc = aic + (2 * k * (k + 1)) / (n - k - 1) if n > k + 1 else np.inf\n",
    "        \n",
    "        return {\n",
    "            'name': 'Normal',\n",
    "            'params': {'mu': mu, 'sigma': sigma},\n",
    "            'aic': aic,\n",
    "            'aicc': aicc,\n",
    "            'pdf': lambda x: stats.norm.pdf(x, mu, sigma),\n",
    "            'cdf': lambda x: stats.norm.cdf(x, mu, sigma),\n",
    "            'ppf': lambda q: stats.norm.ppf(q, mu, sigma),\n",
    "            'is_fallback': False\n",
    "        }\n",
    "    \n",
    "    def fit_generalized_t(self, data):\n",
    "        # Initial parameters: loc, scale, shape1 (nu), shape2 (p)\n",
    "        def neg_log_likelihood(params):\n",
    "            # We fix loc=0 and only optimize scale, nu, p\n",
    "            scale, nu, p = params\n",
    "            loc = 0  # Fixed at zero\n",
    "            \n",
    "            if scale <= 0 or nu <= 0 or p <= 0:\n",
    "                return np.inf\n",
    "            \n",
    "            try:\n",
    "                nu_pow = nu ** (1/p)  # nu^(1/p)\n",
    "                p1 = p / (2 * nu_pow * self._beta_func(1/p, nu)) \n",
    "                p2 = 1 / scale\n",
    "                p3 = np.power(1 + (1/nu) * np.power(np.abs(data - loc) / scale, p), -(nu + 1/p))  \n",
    "                \n",
    "                # Avoid log(0)\n",
    "                p3 = np.clip(p3, 1e-10, None)\n",
    "                loglik = np.log(p1) + np.log(p2) + np.log(p3)\n",
    "                return -np.sum(loglik)\n",
    "            except:\n",
    "                return np.inf\n",
    "                \n",
    "        # Initial guesses (without loc as it's fixed to 0)\n",
    "        initial_guess = [np.std(data, ddof=1), 5.0, 2.0]  # Unbiased estimation with ddof=1\n",
    "        \n",
    "        try:\n",
    "            result = minimize(neg_log_likelihood, initial_guess, \n",
    "                             bounds=[(1e-6, np.inf), (1e-6, np.inf), (1e-6, np.inf)],\n",
    "                             method='L-BFGS-B')\n",
    "            \n",
    "            scale, nu, p = result.x\n",
    "            loc = 0  # Fixed at zero\n",
    "            \n",
    "            n = len(data)\n",
    "            k = 3  # Number of parameters: scale, nu, p (loc is fixed)\n",
    "            loglik = -neg_log_likelihood(result.x)\n",
    "            \n",
    "            # AIC = 2k - 2ln(L)\n",
    "            aic = 2 * k - 2 * loglik\n",
    "            # AICC = AIC + 2k(k+1)/(n-k-1)\n",
    "            aicc = aic + (2 * k * (k + 1)) / (n - k - 1) if n > k + 1 else np.inf\n",
    "            \n",
    "            # Pre-compute some values for efficiency\n",
    "            grid_size = 1000\n",
    "            x_grid = np.linspace(-10*scale + loc, 10*scale + loc, grid_size)\n",
    "            pdf_grid = np.zeros(grid_size)\n",
    "            \n",
    "            for i in range(grid_size):\n",
    "                pdf_grid[i] = self._gen_t_pdf(x_grid[i], loc, scale, nu, p)\n",
    "                \n",
    "            # Compute CDF grid using cumulative trapezoidal integration\n",
    "            cdf_grid = np.zeros(grid_size)\n",
    "            for i in range(1, grid_size):\n",
    "                cdf_grid[i] = cdf_grid[i-1] + 0.5 * (pdf_grid[i] + pdf_grid[i-1]) * (x_grid[i] - x_grid[i-1])\n",
    "                \n",
    "            # Normalize CDF to ensure it ends at 1.0\n",
    "            if cdf_grid[-1] > 0:\n",
    "                cdf_grid = cdf_grid / cdf_grid[-1]\n",
    "            \n",
    "            # Create interpolation functions for faster lookups\n",
    "            cdf_interp = lambda x: np.interp(x, x_grid, cdf_grid)\n",
    "            ppf_interp = lambda q: np.interp(q, cdf_grid, x_grid)\n",
    "            \n",
    "            # Create the functions using the fitted parameters\n",
    "            return {\n",
    "                'name': 'Generalized_T',\n",
    "                'params': {'loc': loc, 'scale': scale, 'nu': nu, 'p': p},\n",
    "                'aic': aic,\n",
    "                'aicc': aicc,\n",
    "                'pdf': lambda x: self._gen_t_pdf(x, loc, scale, nu, p),\n",
    "                'cdf': cdf_interp,\n",
    "                'ppf': ppf_interp,\n",
    "                'is_fallback': False\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # If optimization fails, return normal distribution as fallback\n",
    "            print(f\"Generalized T fitting failed: {str(e)}\")\n",
    "            normal_fit = self.fit_normal(data)\n",
    "            normal_fit['is_fallback'] = True\n",
    "            return normal_fit\n",
    "    \n",
    "    def _beta_func(self, a, b):\n",
    "        # Safe implementation of beta function\n",
    "        try:\n",
    "            return gamma(a) * gamma(b) / gamma(a + b)\n",
    "        except:\n",
    "            return np.inf\n",
    "    \n",
    "\n",
    "    def _gen_t_pdf(self, x, loc, scale, nu, p):\n",
    "        try:\n",
    "\n",
    "            nu_pow = nu ** (1/p)  # nu^(1/p)\n",
    "            p1 = p / (2 * nu_pow * self._beta_func(1/p, nu))  \n",
    "            p2 = 1 / scale\n",
    "            p3 = np.power(1 + (1/nu) * np.power(np.abs(x - loc) / scale, p), -(nu + 1/p))  \n",
    "            return p1 * p2 * p3\n",
    "        except:\n",
    "            # \n",
    "            if np.isscalar(x):\n",
    "                return 1e-10\n",
    "            else:\n",
    "                return np.ones_like(x) * 1e-10\n",
    "        \n",
    "    def fit_nig(self, data):\n",
    "        # Normal Inverse Gaussian distribution with mean 0\n",
    "        def nig_loglikelihood(params):\n",
    "            # We fix mu=0 and only optimize alpha, beta, delta\n",
    "            alpha, beta, delta = params\n",
    "            mu = 0  # Fixed at zero\n",
    "            \n",
    "            if alpha <= 0 or delta <= 0 or np.abs(beta) >= alpha:\n",
    "                return np.inf\n",
    "            \n",
    "            try:\n",
    "                gamma_param = np.sqrt(alpha**2 - beta**2)\n",
    "                \n",
    "                term1 = np.log(alpha) - np.log(np.pi) + np.log(delta)\n",
    "                # Calculate terms separately for better numerical stability\n",
    "                term2 = np.log(kv(1, alpha * np.sqrt(delta**2 + (data - mu)**2)))\n",
    "                term3 = beta * (data - mu) + delta * gamma_param\n",
    "                # Add the missing term in the log-likelihood\n",
    "                term4 = -0.5 * np.log(delta**2 + (data - mu)**2)\n",
    "                \n",
    "                # Handle potential NaN values\n",
    "                log_vals = term1 + term2 + term3 + term4\n",
    "                return np.sum(np.nan_to_num(log_vals, nan=-np.inf))\n",
    "            except:\n",
    "                return np.inf\n",
    "        \n",
    "        def neg_nig_loglikelihood(params):\n",
    "            return -nig_loglikelihood(params)\n",
    "        \n",
    "        # Initial guesses\n",
    "        std = np.std(data, ddof=1)  # Unbiased estimation with ddof=1\n",
    "        skew = stats.skew(data)\n",
    "        kurtosis = stats.kurtosis(data)\n",
    "        \n",
    "        # Convert moments to NIG parameters (rough estimation)\n",
    "        gamma_est = np.sqrt(3 * kurtosis / 5) if kurtosis > 0 else 1.0\n",
    "        gamma_est = max(gamma_est, 1e-3)\n",
    "        \n",
    "        alpha_est = gamma_est / std if std > 0 else 1.0\n",
    "        alpha_est = max(alpha_est, 1e-3)\n",
    "        \n",
    "        if skew == 0:\n",
    "            beta_est = 0\n",
    "        else:\n",
    "            beta_denom = np.sqrt(3 * kurtosis - 5 * skew**2)\n",
    "            beta_est = (skew * alpha_est / beta_denom) if beta_denom > 0 else 0\n",
    "            \n",
    "        # Ensure |beta| < alpha\n",
    "        if abs(beta_est) >= alpha_est:\n",
    "            beta_est = 0.9 * alpha_est * np.sign(beta_est) if beta_est != 0 else 0\n",
    "            \n",
    "        delta_est = 1 / (std * np.sqrt(1 + (skew**2 / 3))) if std > 0 else 1.0\n",
    "        delta_est = max(delta_est, 1e-3)\n",
    "        \n",
    "        initial_guess = [alpha_est, beta_est, delta_est]\n",
    "        \n",
    "        # Ensure initial guesses are valid\n",
    "        if np.isnan(initial_guess).any() or alpha_est <= np.abs(beta_est):\n",
    "            initial_guess = [1.0, 0.0, std if std > 0 else 1.0]\n",
    "        \n",
    "        bounds = [(1e-3, None), (None, None), (1e-3, None)]\n",
    "        \n",
    "        try:\n",
    "\n",
    "            constraints = [\n",
    "                {'type': 'ineq', 'fun': lambda x: x[0] - np.abs(x[1])}  # alpha >= |beta|\n",
    "            ]\n",
    "            result = minimize(\n",
    "                neg_nig_loglikelihood, \n",
    "                initial_guess, \n",
    "                bounds=bounds, \n",
    "                constraints=constraints,  # \n",
    "                method='SLSQP'  # \n",
    "            )\n",
    "\n",
    "            \n",
    "            alpha, beta, delta = result.x\n",
    "            mu = 0  # Fixed at zero\n",
    "            \n",
    "            n = len(data)\n",
    "            k = 3  # Parameter count: alpha, beta, delta (mu is fixed)\n",
    "            loglik = nig_loglikelihood(result.x)\n",
    "            \n",
    "            # AIC = 2k - 2ln(L)\n",
    "            aic = 2 * k - 2 * loglik\n",
    "            # AICC = AIC + 2k(k+1)/(n-k-1)\n",
    "            aicc = aic + (2 * k * (k + 1)) / (n - k - 1) if n > k + 1 else np.inf\n",
    "            \n",
    "            # Pre-compute grid values for faster CDF and PPF\n",
    "            grid_size = 1000\n",
    "            x_grid = np.linspace(-10*delta + mu, 10*delta + mu, grid_size)\n",
    "            pdf_grid = np.zeros(grid_size)\n",
    "            \n",
    "            for i in range(grid_size):\n",
    "                pdf_grid[i] = self._nig_pdf(x_grid[i], alpha, beta, mu, delta)\n",
    "                \n",
    "            # Compute CDF grid using cumulative trapezoidal integration\n",
    "            cdf_grid = np.zeros(grid_size)\n",
    "            for i in range(1, grid_size):\n",
    "                cdf_grid[i] = cdf_grid[i-1] + 0.5 * (pdf_grid[i] + pdf_grid[i-1]) * (x_grid[i] - x_grid[i-1])\n",
    "                \n",
    "            # Normalize CDF to ensure it ends at 1.0\n",
    "            if cdf_grid[-1] > 0:\n",
    "                cdf_grid = cdf_grid / cdf_grid[-1]\n",
    "            \n",
    "            # Create interpolation functions for faster lookups\n",
    "            cdf_interp = lambda x: np.interp(x, x_grid, cdf_grid)\n",
    "            ppf_interp = lambda q: np.interp(q, cdf_grid, x_grid)\n",
    "            \n",
    "            return {\n",
    "                'name': 'NIG',\n",
    "                'params': {'alpha': alpha, 'beta': beta, 'mu': mu, 'delta': delta},\n",
    "                'aic': aic,\n",
    "                'aicc': aicc,\n",
    "                'pdf': lambda x: self._nig_pdf(x, alpha, beta, mu, delta),\n",
    "                'cdf': cdf_interp,\n",
    "                'ppf': ppf_interp,\n",
    "                'is_fallback': False\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # If optimization fails, return normal distribution as fallback\n",
    "            print(f\"NIG fitting failed: {str(e)}\")\n",
    "            normal_fit = self.fit_normal(data)\n",
    "            normal_fit['is_fallback'] = True\n",
    "            return normal_fit\n",
    "    \n",
    "    def _nig_pdf(self, x, alpha, beta, mu, delta):\n",
    "        try:\n",
    "            gamma_param = np.sqrt(alpha**2 - beta**2)\n",
    "            numerator = alpha * delta * kv(1, alpha * np.sqrt(delta**2 + (x - mu)**2))\n",
    "            numerator *= np.exp(delta * gamma_param + beta * (x - mu))\n",
    "            denominator = np.pi * np.sqrt(delta**2 + (x - mu)**2)\n",
    "            \n",
    "            # Handle potential division by zero or invalid values\n",
    "            result = numerator / denominator\n",
    "            \n",
    "            # Replace NaN or inf values with small value\n",
    "            if np.isscalar(result):\n",
    "                if np.isnan(result) or np.isinf(result):\n",
    "                    return 1e-10\n",
    "                return result\n",
    "            else:\n",
    "                return np.nan_to_num(result, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "                \n",
    "        except:\n",
    "            # Return very small value on error\n",
    "            if np.isscalar(x):\n",
    "                return 1e-10\n",
    "            else:\n",
    "                return np.ones_like(x) * 1e-10\n",
    "    \n",
    "    def fit_skew_normal(self, data):\n",
    "        # Fit skew normal distribution with mean fixed at 0\n",
    "        def skew_normal_loglikelihood(params):\n",
    "            shape, scale = params\n",
    "            loc = 0  # Fixed at zero\n",
    "            \n",
    "            if scale <= 0:\n",
    "                return np.inf\n",
    "                \n",
    "            try:\n",
    "                loglik = np.sum(stats.skewnorm.logpdf(data, shape, loc, scale))\n",
    "                return -loglik\n",
    "            except:\n",
    "                return np.inf\n",
    "        \n",
    "        # Initial guesses\n",
    "        shape_init = stats.skew(data) * 2  # Rough approximation\n",
    "        scale_init = np.std(data, ddof=1)  # Unbiased estimation with ddof=1\n",
    "        \n",
    "        initial_guess = [shape_init, scale_init]\n",
    "        bounds = [(None, None), (1e-6, None)]\n",
    "        \n",
    "        try:\n",
    "            result = minimize(skew_normal_loglikelihood, initial_guess, \n",
    "                             bounds=bounds, method='L-BFGS-B')\n",
    "            \n",
    "            shape, scale = result.x\n",
    "            loc = 0  # Fixed at zero\n",
    "            \n",
    "            n = len(data)\n",
    "            k = 2  # Parameter count: shape and scale (loc is fixed)\n",
    "            loglik = -skew_normal_loglikelihood(result.x)\n",
    "            \n",
    "            # AIC = 2k - 2ln(L)\n",
    "            aic = 2 * k - 2 * loglik\n",
    "            # AICC = AIC + 2k(k+1)/(n-k-1)\n",
    "            aicc = aic + (2 * k * (k + 1)) / (n - k - 1) if n > k + 1 else np.inf\n",
    "            \n",
    "            return {\n",
    "                'name': 'Skew_Normal',\n",
    "                'params': {'shape': shape, 'loc': loc, 'scale': scale},\n",
    "                'aic': aic,\n",
    "                'aicc': aicc,\n",
    "                'pdf': lambda x: stats.skewnorm.pdf(x, shape, loc, scale),\n",
    "                'cdf': lambda x: stats.skewnorm.cdf(x, shape, loc, scale),\n",
    "                'ppf': lambda q: stats.skewnorm.ppf(q, shape, loc, scale),\n",
    "                'is_fallback': False\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # If optimization fails, return normal distribution as fallback\n",
    "            print(f\"Skew Normal fitting failed: {str(e)}\")\n",
    "            normal_fit = self.fit_normal(data)\n",
    "            normal_fit['is_fallback'] = True\n",
    "            return normal_fit\n",
    "    \n",
    "    def fit_best_distribution(self, data, symbol):\n",
    "        best_fit = None\n",
    "        best_aicc = np.inf\n",
    "        \n",
    "        for name, fit_func in self.distributions.items():\n",
    "            try:\n",
    "                dist_fit = fit_func(data)\n",
    "                if dist_fit['aicc'] < best_aicc:  \n",
    "                    best_aicc = dist_fit['aicc']\n",
    "                    best_fit = dist_fit\n",
    "            except Exception as e:\n",
    "                print(f\"Error fitting {name} distribution for {symbol}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # If no distribution fits well, use normal as fallback\n",
    "        if best_fit is None:\n",
    "            best_fit = self.fit_normal(data)\n",
    "            best_fit['is_fallback'] = True\n",
    "            self.fallback_flags[symbol] = True\n",
    "        \n",
    "        return best_fit\n",
    "\n",
    "# Parallel function for simulating a single stock's returns\n",
    "def simulate_stock_returns(u, best_fit, n_scenarios):\n",
    "    \"\"\"\n",
    "    Simulate returns for a single stock using its fitted distribution\n",
    "    \"\"\"\n",
    "    return best_fit['ppf'](u)\n",
    "\n",
    "# Risk model calculation\n",
    "def calculate_risk_metrics(pre_holding, portfolio_weights, last_day_2023):\n",
    "    # Initialize distribution fitter\n",
    "    dist_fitter = DistributionFitter()\n",
    "    \n",
    "    # Dictionary to store best fit models for each stock\n",
    "    best_fits = {}\n",
    "    fallback_stocks = []\n",
    "    \n",
    "    # Fit distributions to each stock's returns\n",
    "    print(\"Fitting distributions to each stock...\")\n",
    "    for symbol in pre_holding.columns:\n",
    "        data = pre_holding[symbol].dropna().values\n",
    "        \n",
    "        if len(data) > 30:  # Ensure enough data points\n",
    "            print(f\"Fitting distributions for {symbol}...\")\n",
    "            best_fit = dist_fitter.fit_best_distribution(data, symbol)  # Pass symbol for error reporting\n",
    "            best_fits[symbol] = best_fit\n",
    "            \n",
    "            if best_fit['is_fallback']:\n",
    "                fallback_stocks.append(symbol)\n",
    "    \n",
    "    if fallback_stocks:\n",
    "        print(\"\\nWARNING: The following stocks used Normal distribution as fallback due to fitting failures:\")\n",
    "        for symbol in fallback_stocks:\n",
    "            print(f\"  - {symbol}\")\n",
    "    \n",
    "    # Calculate correlation matrix for Gaussian Copula\n",
    "    correlation_matrix = pre_holding.corr()\n",
    "    \n",
    "    # Ensure correlation matrix is positive definite using Higham's algorithm\n",
    "    if not is_pd(correlation_matrix.values):\n",
    "        print(\"Making correlation matrix positive definite using Higham's algorithm...\")\n",
    "        pd_corr_matrix = nearest_pd(correlation_matrix.values)\n",
    "        correlation_matrix = pd.DataFrame(\n",
    "            pd_corr_matrix, \n",
    "            index=correlation_matrix.index, \n",
    "            columns=correlation_matrix.columns\n",
    "        )\n",
    "    \n",
    "    # Calculate VaR and ES for each portfolio using fitted models and Gaussian Copula\n",
    "    var_es_results = {}\n",
    "    \n",
    "    # Generate large number of scenarios\n",
    "    n_scenarios = 10000\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate correlated normal variables using Gaussian Copula\n",
    "    normal_samples = np.random.multivariate_normal(\n",
    "        mean=np.zeros(len(correlation_matrix)),\n",
    "        cov=correlation_matrix.values,\n",
    "        size=n_scenarios\n",
    "    )\n",
    "    uniform_samples = stats.norm.cdf(normal_samples)\n",
    "    \n",
    "    # For each portfolio, calculate VaR and ES\n",
    "    print(\"\\nCalculating VaR and ES for each portfolio...\")\n",
    "    for portfolio, weights in portfolio_weights.items():\n",
    "        print(f\"Processing portfolio: {portfolio}\")\n",
    "        \n",
    "        # Get the stocks in the portfolio\n",
    "        stocks = list(weights.keys())\n",
    "        \n",
    "        # Filter to only stocks with fitted distributions\n",
    "        stocks = [s for s in stocks if s in best_fits]\n",
    "        \n",
    "        if not stocks:\n",
    "            print(f\"  Warning: No stocks with fitted distributions in portfolio {portfolio}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate simulated returns using the fitted distributions\n",
    "        simulated_returns_fitted = np.zeros((n_scenarios, len(stocks)))\n",
    "        simulated_returns_normal = np.zeros((n_scenarios, len(stocks)))\n",
    "        \n",
    "        # Use parallel processing for the simulation\n",
    "        results_fitted = []\n",
    "        \n",
    "        for i, symbol in enumerate(stocks):\n",
    "            # For fitted distributions\n",
    "            u = uniform_samples[:, list(correlation_matrix.columns).index(symbol)]\n",
    "            \n",
    "            # Store stock index, its weight, and the uniform samples for parallel processing\n",
    "            results_fitted.append((i, symbol, u))\n",
    "            \n",
    "            # For multivariate normal (simpler, do in-place)\n",
    "            std = np.std(pre_holding[symbol].dropna(), ddof=1)  # Unbiased estimation with ddof=1\n",
    "            simulated_returns_normal[:, i] = stats.norm.ppf(u, loc=0, scale=std)\n",
    "        \n",
    "        # Process fitted distributions in parallel\n",
    "        print(f\"  Simulating returns for portfolio {portfolio}...\")\n",
    "        \n",
    "        # Function to process a single stock\n",
    "        def process_stock(result_tuple):\n",
    "            i, symbol, u = result_tuple\n",
    "            return i, simulate_stock_returns(u, best_fits[symbol], len(u))\n",
    "        \n",
    "        # Process in parallel\n",
    "        try:\n",
    "            parallel_results = Parallel(n_jobs=-1)(\n",
    "                delayed(process_stock)(res) for res in results_fitted\n",
    "            )\n",
    "            \n",
    "            # Assign results back to the array\n",
    "            for i, returns in parallel_results:\n",
    "                simulated_returns_fitted[:, i] = returns\n",
    "        except Exception as e:\n",
    "            print(f\"Parallel processing failed: {str(e)}. Falling back to sequential processing.\")\n",
    "            # Fallback to sequential processing\n",
    "            for i, symbol, u in results_fitted:\n",
    "                simulated_returns_fitted[:, i] = best_fits[symbol]['ppf'](u)\n",
    "        \n",
    "        # Calculate portfolio returns\n",
    "        portfolio_returns_fitted = np.zeros(n_scenarios)\n",
    "        portfolio_returns_normal = np.zeros(n_scenarios)\n",
    "        \n",
    "        for i, symbol in enumerate(stocks):\n",
    "            weight = weights[symbol]\n",
    "            portfolio_returns_fitted += weight * simulated_returns_fitted[:, i]\n",
    "            portfolio_returns_normal += weight * simulated_returns_normal[:, i]\n",
    "        \n",
    "        # Calculate 1-day VaR at 95% confidence level\n",
    "        var_95_fitted = -np.percentile(portfolio_returns_fitted, 5)\n",
    "        es_95_fitted = -np.mean(portfolio_returns_fitted[portfolio_returns_fitted <= -var_95_fitted])\n",
    "        \n",
    "        var_95_normal = -np.percentile(portfolio_returns_normal, 5)\n",
    "        es_95_normal = -np.mean(portfolio_returns_normal[portfolio_returns_normal <= -var_95_normal])\n",
    "        \n",
    "        # Store results\n",
    "        var_es_results[portfolio] = {\n",
    "            'Fitted': {\n",
    "                'VaR_95': var_95_fitted,\n",
    "                'ES_95': es_95_fitted\n",
    "            },\n",
    "            'Normal': {\n",
    "                'VaR_95': var_95_normal,\n",
    "                'ES_95': es_95_normal\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return best_fits, var_es_results\n",
    "\n",
    "\n",
    "prices_df, portfolio_df = load_data()\n",
    "portfolio_weights, last_day_2023 = calculate_weights(prices_df, portfolio_df)\n",
    "returns_df = prices_df.pct_change().dropna()\n",
    "pre_returns, holding_returns = split_data(returns_df)\n",
    "pre_returns_centered = pre_returns - pre_returns.mean()\n",
    "\n",
    "print(\"Calculating risk metrics...\")\n",
    "best_fits, var_es_results = calculate_risk_metrics(pre_returns_centered, portfolio_weights, last_day_2023)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest Fit Distribution for Each Stock (using AICC criterion):\")\n",
    "print(\"-\" * 80)\n",
    "for symbol, fit in best_fits.items():\n",
    "    fallback_note = \" (FALLBACK: fitting failed)\" if fit['is_fallback'] else \"\"\n",
    "    print(f\"Symbol: {symbol}{fallback_note}\")\n",
    "    print(f\"  Best Fit Model: {fit['name']}\")\n",
    "    print(f\"  Parameters: {fit['params']}\")\n",
    "    print(f\"  AICC: {fit['aicc']:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nVaR and ES Results (1-day, 95% confidence level):\")\n",
    "print(\"-\" * 80)\n",
    "for portfolio, results in var_es_results.items():\n",
    "    print(f\"Portfolio: {portfolio}\")\n",
    "    print(f\"  Using Fitted Distributions with Gaussian Copula:\")\n",
    "    print(f\"    VaR: {results['Fitted']['VaR_95']:.6f}\")\n",
    "    print(f\"    ES: {results['Fitted']['ES_95']:.6f}\")\n",
    "    print(f\"  Using Multivariate Normal:\")\n",
    "    print(f\"    VaR: {results['Normal']['VaR_95']:.6f}\")\n",
    "    print(f\"    ES: {results['Normal']['ES_95']:.6f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373 -0.035955   0.194483\n",
      "1  Return Attribution  0.233480 -0.038997   0.194483\n",
      "2     Vol Attribution  0.006688  0.000186   0.006874 \n",
      "\n",
      "B Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373  0.027481   0.256825\n",
      "1  Return Attribution  0.225270  0.031555   0.256825\n",
      "2     Vol Attribution  0.005892  0.000613   0.006505 \n",
      "\n",
      "C Portfolio Attribution\n",
      "                Value       SPY     Alpha  Portfolio\n",
      "0         TotalReturn  0.261373  0.072173   0.337944\n",
      "1  Return Attribution  0.256651  0.081293   0.337944\n",
      "2     Vol Attribution  0.007088  0.000914   0.008002 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class RiskParityOptimizer:\n",
    "    \"\"\"\n",
    "    Risk-Parity Portfolio Optimizer Based on Expected Shortfall (ES) Risk Measurement\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, best_fits: Dict[str, Dict], returns_df: pd.DataFrame, confidence_level=0.95, num_samples=100000, seed=42):\n",
    "        \"\"\"Initialize the optimizer \n",
    "        \n",
    "        Args:\n",
    "            best_fits: Information on the best-fit distribution for each asset\n",
    "            returns_df: Historical data frame of asset returns, with each column representing an asset\n",
    "            confidence_level: Confidence level for ES calculation\n",
    "            num_samples: Number of samples for Monte Carlo simulation\n",
    "            seed: Random number seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.best_fits = best_fits\n",
    "        self.returns_df = returns_df\n",
    "        self.confidence_level = confidence_level\n",
    "        self.num_samples = num_samples\n",
    "        self.seed = seed\n",
    "        self.assets = list(best_fits.keys())\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "    \n",
    "    def simulate_returns(self) -> np.ndarray:\n",
    "        \"\"\"Generate simulated returns by using the best-fitting distribution for each asset and the correlations among them. \n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Simulated return matrix\n",
    "        \"\"\"\n",
    "        random_normal = np.random.normal(0, 1, size=(self.num_samples, len(self.assets)))\n",
    "        \n",
    "        assets_subset = [a for a in self.assets if a in self.returns_df.columns]\n",
    "        spearman_corr = self.returns_df[assets_subset].corr(method='spearman').values\n",
    "        \n",
    "        try:\n",
    "            chol = np.linalg.cholesky(spearman_corr)\n",
    "        except np.linalg.LinAlgError:\n",
    "            eigvals, eigvecs = np.linalg.eigh(spearman_corr)\n",
    "            eigvals = np.maximum(eigvals, 1e-8)  \n",
    "            fixed_corr = eigvecs @ np.diag(eigvals) @ eigvecs.T\n",
    "            d = np.sqrt(np.diag(fixed_corr))\n",
    "            fixed_corr = fixed_corr / np.outer(d, d)\n",
    "            chol = np.linalg.cholesky(fixed_corr)\n",
    "\n",
    "        correlated_normal = random_normal @ chol.T\n",
    "        \n",
    "        uniform_samples = norm.cdf(correlated_normal)\n",
    "        \n",
    "        simulated_returns = np.zeros((self.num_samples, len(self.assets)))\n",
    "        \n",
    "        for i, asset in enumerate(self.assets):\n",
    "            ppf_func = self.best_fits[asset]['ppf']\n",
    "            simulated_returns[:, i] = ppf_func(uniform_samples[:, i])\n",
    "        \n",
    "        return simulated_returns\n",
    "    \n",
    "    def calculate_portfolio_returns(self, weights: np.ndarray, sim_returns: np.ndarray) -> np.ndarray:\n",
    "        return sim_returns @ weights\n",
    "    \n",
    "    def calculate_es(self, returns: np.ndarray) -> float:\n",
    "        var_quantile = np.quantile(returns, 1 - self.confidence_level)\n",
    "        es = -returns[returns <= var_quantile].mean() \n",
    "        return es  \n",
    "    \n",
    "    def calculate_marginal_risk_contribution(self, weights: np.ndarray, sim_returns: np.ndarray) -> np.ndarray:\n",
    "        portfolio_returns = self.calculate_portfolio_returns(weights, sim_returns)\n",
    "        var_quantile = np.quantile(portfolio_returns, 1 - self.confidence_level)\n",
    "        \n",
    "        tail_indices = portfolio_returns <= var_quantile\n",
    "        \n",
    "        marginal_contributions = np.zeros(len(weights))\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            asset_losses = -sim_returns[tail_indices, i]  \n",
    "            marginal_contributions[i] = weights[i] * np.mean(asset_losses)\n",
    "        \n",
    "        return marginal_contributions\n",
    "    \n",
    "    def calculate_risk_contribution(self, weights: np.ndarray, sim_returns: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate the risk contribution of each asset.\n",
    "\n",
    "        Args:\n",
    "            weights (np.ndarray): Property rights weights\n",
    "            sim_returns (np.ndarray): Simulated return matrix \n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The risk contribution of each asset\n",
    "        \"\"\"\n",
    "        marginal_risk = self.calculate_marginal_risk_contribution(weights, sim_returns)\n",
    "        return weights * marginal_risk\n",
    "    \n",
    "    def risk_concentration_objective(self, weights: np.ndarray, sim_returns: np.ndarray) -> float:\n",
    "        \"\"\"Minimize the difference between the risk contribution and the target risk contribution.\n",
    "\n",
    "        Args:\n",
    "            weights (np.ndarray): Property weights\n",
    "            sim_returns (np.ndarray): Simulated return matrix\n",
    "\n",
    "        Returns:\n",
    "            float: Risk Concentration Target Value\n",
    "        \"\"\"\n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        # Calculate the risk contribution of each asset.\n",
    "        risk_contrib = self.calculate_risk_contribution(weights, sim_returns)\n",
    "        \n",
    "        # Target risk contribution: equal risk contribution for each asset\n",
    "        target_risk_contrib = np.ones(len(weights)) / len(weights)\n",
    "        \n",
    "        concentration = np.sum((risk_contrib / np.sum(risk_contrib) - target_risk_contrib) ** 2)\n",
    "        \n",
    "        return concentration\n",
    "    \n",
    "    def optimize(self, ticker_list: List[str] = None) -> Dict[str, float]:\n",
    "        \"\"\"Optimize the investment portfolio to achieve risk parity. \n",
    "\n",
    "        Args:\n",
    "            ticker_list (List[str], optional): The list of assets to be included in the investment portfolio. \n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, float]: The optimized dictionary of asset weights\n",
    "        \"\"\"\n",
    "\n",
    "        if ticker_list is None:\n",
    "            ticker_list = self.assets\n",
    "        else:\n",
    "\n",
    "            assert all(ticker in self.best_fits for ticker in ticker_list), \"Some tickers are not included in best_fits.\"\n",
    "        \n",
    "\n",
    "        \n",
    "        asset_indices = [self.assets.index(ticker) for ticker in ticker_list]\n",
    "        sim_returns = self.simulate_returns()[:, asset_indices]\n",
    "        \n",
    "        initial_weights = np.ones(len(ticker_list)) / len(ticker_list)\n",
    "        \n",
    "        # weight constraint\n",
    "        bounds = [(0.0, 1.0) for _ in range(len(ticker_list))]\n",
    "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]\n",
    "        \n",
    "        result = optimize.minimize(\n",
    "            lambda w: self.risk_concentration_objective(w, sim_returns),\n",
    "            initial_weights,\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints,\n",
    "            options={'ftol': 1e-9, 'disp': False, 'maxiter': 1000}\n",
    "        )\n",
    "        \n",
    "        optimal_weights = result.x / np.sum(result.x)\n",
    "        \n",
    "        return {ticker: weight for ticker, weight in zip(ticker_list, optimal_weights)}\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "optimizer = RiskParityOptimizer(best_fits, returns_df, confidence_level=0.95)\n",
    "\n",
    "\n",
    "sub_portfolios = {}\n",
    "for p in portfolio_df['Portfolio'].unique():\n",
    "    sub_portfolios[p] = list(portfolio_df[portfolio_df['Portfolio'] == p]['Symbol'].values)\n",
    "\n",
    "port_weights = {}\n",
    "for name, tickers in sub_portfolios.items():\n",
    "    weights = optimizer.optimize(tickers)\n",
    "    port_weights[name] = weights\n",
    "\n",
    "betas_dict = dict(zip(capm_betas['Symbol'], capm_betas['Beta']))\n",
    "\n",
    "# Rerun the attribution from Part 1 using the new optimal portfolios and the previously fit CAPM beta.\n",
    "all_results = {}\n",
    "for port, weights in port_weights.items():\n",
    "    # Get stocks in this portfolio\n",
    "    p_stocks = list(weights.keys())\n",
    "\n",
    "    # Convert weights to array\n",
    "    p_w = np.array([weights[stock] for stock in p_stocks])\n",
    "\n",
    "    \n",
    "    # Get returns for these stocks\n",
    "    p_stock_returns = realized_returns[p_stocks]\n",
    "    \n",
    "    p_betas = np.array([betas_dict[stock] for stock in p_stocks])\n",
    "    # Run attribution analysis\n",
    "    p_attrib = expost_factor(p_w, p_stock_returns, realized_spy, p_betas)\n",
    "    print(f\"{port} Portfolio Attribution\")\n",
    "    print(p_attrib.attribution, '\\n')\n",
    "    \n",
    "    all_results[port] = p_attrib.attribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'SPY': 0.009740158191839874,\n",
       "  'AAPL': 0.010346087478489925,\n",
       "  'NVDA': 0.007331611256518578,\n",
       "  'MSFT': 0.008856227620683397,\n",
       "  'AMZN': 0.00792905817280749,\n",
       "  'META': 0.00787432961755863,\n",
       "  'GOOGL': 0.008748186004266783,\n",
       "  'AVGO': 0.008070717284147091,\n",
       "  'TSLA': 0.01675933149726611,\n",
       "  'GOOG': 0.008677822471626108,\n",
       "  'BRK-B': 0.011095581588595306,\n",
       "  'JPM': 0.009394516800598524,\n",
       "  'LLY': 0.011772112887211469,\n",
       "  'V': 0.010978951905577674,\n",
       "  'XOM': 0.01178860069171267,\n",
       "  'UNH': 0.015145241167794418,\n",
       "  'MA': 0.010170250417754705,\n",
       "  'COST': 0.010279404852655445,\n",
       "  'PG': 0.014796765400399328,\n",
       "  'WMT': 0.01480749079389188,\n",
       "  'HD': 0.009204655389952023,\n",
       "  'NFLX': 0.007864507825361883,\n",
       "  'JNJ': 0.014190100360333562,\n",
       "  'ABBV': 0.013313933535130256,\n",
       "  'CRM': 0.008209488607251769,\n",
       "  'BAC': 0.008052784404371802,\n",
       "  'ORCL': 0.00865906917421249,\n",
       "  'MRK': 0.016279364902981135,\n",
       "  'CVX': 0.011559390697362287,\n",
       "  'KO': 0.014564853731327617,\n",
       "  'CSCO': 0.00976137566638547,\n",
       "  'WFC': 0.008470826041719759,\n",
       "  'ACN': 0.009347104164713153,\n",
       "  'NOW': 0.007732389045208798,\n",
       "  'MCD': 0.0131455387990462,\n",
       "  'PEP': 0.0148101915694524,\n",
       "  'IBM': 0.011386070898651374,\n",
       "  'DIS': 0.008883817310897183,\n",
       "  'TMO': 0.009396490799582054,\n",
       "  'LIN': 0.00970026544537352,\n",
       "  'ABT': 0.011169510861562695,\n",
       "  'AMD': 0.007017249695358713,\n",
       "  'ADBE': 0.007711373600445679,\n",
       "  'PM': 0.012872739835432655,\n",
       "  'ISRG': 0.007857243214519815,\n",
       "  'GE': 0.009179033252302507,\n",
       "  'GS': 0.00836210159279158,\n",
       "  'INTU': 0.00762575855399801,\n",
       "  'CAT': 0.007950650778080576,\n",
       "  'QCOM': 0.007757436159108727,\n",
       "  'TXN': 0.008439710567196664,\n",
       "  'VZ': 0.013063869323952749,\n",
       "  'AXP': 0.008046029775136384,\n",
       "  'T': 0.012331566367034225,\n",
       "  'BKNG': 0.009019750248088026,\n",
       "  'SPGI': 0.008613064543828267,\n",
       "  'MS': 0.008061837658312424,\n",
       "  'RTX': 0.011056280602402508,\n",
       "  'PLTR': 0.005269676199807272,\n",
       "  'PFE': 0.011623374562968762,\n",
       "  'BLK': 0.008286324030411601,\n",
       "  'DHR': 0.009458258851141906,\n",
       "  'NEE': 0.010557974579641072,\n",
       "  'HON': 0.009652228214179017,\n",
       "  'CMCSA': 0.009697590862384683,\n",
       "  'PGR': 0.011924721186198835,\n",
       "  'LOW': 0.008585964668685197,\n",
       "  'AMGN': 0.010708618528383635,\n",
       "  'UNP': 0.00931613468948795,\n",
       "  'TJX': 0.01121310600631333,\n",
       "  'AMAT': 0.007656509955908116,\n",
       "  'UBER': 0.008024607349958768,\n",
       "  'C': 0.00830661707076896,\n",
       "  'BSX': 0.011035374117170873,\n",
       "  'ETN': 0.00812636589647453,\n",
       "  'COP': 0.011198747011930287,\n",
       "  'BA': 0.010260551340146659,\n",
       "  'BX': 0.00684993010935889,\n",
       "  'SYK': 0.009425285599486322,\n",
       "  'PANW': 0.008243038815076622,\n",
       "  'ADP': 0.009751363131244044,\n",
       "  'FI': 0.009409263785445137,\n",
       "  'ANET': 0.007515942719510729,\n",
       "  'GILD': 0.01193986657006829,\n",
       "  'BMY': 0.01407258713007933,\n",
       "  'SCHW': 0.007377638075999791,\n",
       "  'TMUS': 0.0124985295117162,\n",
       "  'DE': 0.00896495283337442,\n",
       "  'ADI': 0.008135753413615495,\n",
       "  'VRTX': 0.01087558660600616,\n",
       "  'SBUX': 0.010622517241332311,\n",
       "  'MMC': 0.011072929604874986,\n",
       "  'MDT': 0.010279086510994717,\n",
       "  'CB': 0.011848576762915024,\n",
       "  'LMT': 0.014978385381678765,\n",
       "  'KKR': 0.007023144866585056,\n",
       "  'MU': 0.008260830488565336,\n",
       "  'PLD': 0.008478050453567523,\n",
       "  'LRCX': 0.007388374619486574,\n",
       "  'EQIX': 0.008855749546794531},\n",
       " 'B': {'SPY': 0.00972060639699475,\n",
       "  'AAPL': 0.010479109360207262,\n",
       "  'NVDA': 0.007310439271541808,\n",
       "  'MSFT': 0.0088929001073286,\n",
       "  'AMZN': 0.007936613966813527,\n",
       "  'META': 0.007742013896508337,\n",
       "  'GOOGL': 0.008690551689723333,\n",
       "  'AVGO': 0.007979462136580299,\n",
       "  'TSLA': 0.0168957992853269,\n",
       "  'GOOG': 0.008625061364354675,\n",
       "  'BRK-B': 0.011071713208984807,\n",
       "  'JPM': 0.009552726256637434,\n",
       "  'LLY': 0.0118411280411492,\n",
       "  'V': 0.010995148638900975,\n",
       "  'XOM': 0.011432106524495934,\n",
       "  'UNH': 0.01511485328937076,\n",
       "  'MA': 0.010191536516593184,\n",
       "  'COST': 0.010238449975493967,\n",
       "  'PG': 0.014784711807684335,\n",
       "  'WMT': 0.014587649118302664,\n",
       "  'HD': 0.009090089431312792,\n",
       "  'NFLX': 0.00782585042909936,\n",
       "  'JNJ': 0.014473703328616104,\n",
       "  'ABBV': 0.012756960033784655,\n",
       "  'CRM': 0.00824197365793083,\n",
       "  'BAC': 0.008118432254626615,\n",
       "  'ORCL': 0.008607826311304675,\n",
       "  'MRK': 0.015689931997615033,\n",
       "  'CVX': 0.011491956899706427,\n",
       "  'KO': 0.014640891452959376,\n",
       "  'CSCO': 0.009829813351347643,\n",
       "  'WFC': 0.008608681252299093,\n",
       "  'ACN': 0.009441195126800306,\n",
       "  'NOW': 0.007690876383533885,\n",
       "  'MCD': 0.013199029632327703,\n",
       "  'PEP': 0.014958769925045773,\n",
       "  'IBM': 0.011414449607633943,\n",
       "  'DIS': 0.00888069517470921,\n",
       "  'TMO': 0.009459423723372886,\n",
       "  'LIN': 0.009798591322552983,\n",
       "  'ABT': 0.011404710184481135,\n",
       "  'AMD': 0.007002151691962727,\n",
       "  'ADBE': 0.0077965656505226116,\n",
       "  'PM': 0.0128841225067181,\n",
       "  'ISRG': 0.007901118541691869,\n",
       "  'GE': 0.00926750920675038,\n",
       "  'GS': 0.008291697231320614,\n",
       "  'INTU': 0.007673437633663505,\n",
       "  'CAT': 0.007836178629275053,\n",
       "  'QCOM': 0.007769019181034772,\n",
       "  'TXN': 0.008453689863915408,\n",
       "  'VZ': 0.012736171012898673,\n",
       "  'AXP': 0.008001537446493547,\n",
       "  'T': 0.012126323962964043,\n",
       "  'BKNG': 0.009036889438431133,\n",
       "  'SPGI': 0.008651484831681013,\n",
       "  'MS': 0.008096842107757156,\n",
       "  'RTX': 0.011169009489029281,\n",
       "  'PLTR': 0.005315563242010911,\n",
       "  'PFE': 0.01161875644320801,\n",
       "  'BLK': 0.008359900062646992,\n",
       "  'DHR': 0.009410591169988582,\n",
       "  'NEE': 0.010600657948139068,\n",
       "  'HON': 0.009640046561151099,\n",
       "  'CMCSA': 0.009744339654534312,\n",
       "  'PGR': 0.012063425754717558,\n",
       "  'LOW': 0.00860682049747014,\n",
       "  'AMGN': 0.010587550822488984,\n",
       "  'UNP': 0.009409775708063374,\n",
       "  'TJX': 0.011317148090908868,\n",
       "  'AMAT': 0.007669753641320005,\n",
       "  'UBER': 0.008025407246673331,\n",
       "  'C': 0.008319725334490814,\n",
       "  'BSX': 0.011080435201614074,\n",
       "  'ETN': 0.008171465049998787,\n",
       "  'COP': 0.011061001724969027,\n",
       "  'BA': 0.010086364601937937,\n",
       "  'BX': 0.006881615741276483,\n",
       "  'SYK': 0.009570850285695714,\n",
       "  'PANW': 0.00837245280129183,\n",
       "  'ADP': 0.009791758955588157,\n",
       "  'FI': 0.0093729943495231,\n",
       "  'ANET': 0.007376493192703194,\n",
       "  'GILD': 0.012008790227006615,\n",
       "  'BMY': 0.013837768429678605,\n",
       "  'SCHW': 0.007468742740443386,\n",
       "  'TMUS': 0.012531459991198769,\n",
       "  'DE': 0.008870276044311728,\n",
       "  'ADI': 0.008165881527389294,\n",
       "  'VRTX': 0.010976042665478527,\n",
       "  'SBUX': 0.01053509091355144,\n",
       "  'MMC': 0.011106839255748475,\n",
       "  'MDT': 0.010395808717858323,\n",
       "  'CB': 0.01184318397469039,\n",
       "  'LMT': 0.01547005915411764,\n",
       "  'KKR': 0.006960913739755344,\n",
       "  'MU': 0.008258256844983158,\n",
       "  'PLD': 0.0084449967669228,\n",
       "  'LRCX': 0.007416376790362477,\n",
       "  'EQIX': 0.008854437373929663},\n",
       " 'C': {'SPY': 0.009755683918651057,\n",
       "  'AAPL': 0.010517135726937998,\n",
       "  'NVDA': 0.007374338443167294,\n",
       "  'MSFT': 0.00888828011539867,\n",
       "  'AMZN': 0.007974225196646907,\n",
       "  'META': 0.007831423319091821,\n",
       "  'GOOGL': 0.008893721198967537,\n",
       "  'AVGO': 0.008054968519418074,\n",
       "  'TSLA': 0.016933228052582815,\n",
       "  'GOOG': 0.008805415662701464,\n",
       "  'BRK-B': 0.011117601826969973,\n",
       "  'JPM': 0.00941023872076417,\n",
       "  'LLY': 0.0117295697465211,\n",
       "  'V': 0.010984814891538682,\n",
       "  'XOM': 0.011566098392787936,\n",
       "  'UNH': 0.015024921430621235,\n",
       "  'MA': 0.010211857095367658,\n",
       "  'COST': 0.01040498020012632,\n",
       "  'PG': 0.014725235249455926,\n",
       "  'WMT': 0.014806761178051953,\n",
       "  'HD': 0.009071218604725732,\n",
       "  'NFLX': 0.007894001258632608,\n",
       "  'JNJ': 0.014430012587243878,\n",
       "  'ABBV': 0.013057577681117177,\n",
       "  'CRM': 0.008253006654195606,\n",
       "  'BAC': 0.008038911858909604,\n",
       "  'ORCL': 0.008562094935651118,\n",
       "  'MRK': 0.015711708157539212,\n",
       "  'CVX': 0.01165639414950905,\n",
       "  'KO': 0.014743225447424258,\n",
       "  'CSCO': 0.009897637016992512,\n",
       "  'WFC': 0.008526444739762115,\n",
       "  'ACN': 0.009467746439047013,\n",
       "  'NOW': 0.007698611988743902,\n",
       "  'MCD': 0.0133360370998649,\n",
       "  'PEP': 0.014707480605730221,\n",
       "  'IBM': 0.011263138008348899,\n",
       "  'DIS': 0.00894007411682412,\n",
       "  'TMO': 0.009464338877464822,\n",
       "  'LIN': 0.009703794960769072,\n",
       "  'ABT': 0.011319955105171541,\n",
       "  'AMD': 0.007042862504492604,\n",
       "  'ADBE': 0.007760902912993755,\n",
       "  'PM': 0.012796391795014185,\n",
       "  'ISRG': 0.00789397087426602,\n",
       "  'GE': 0.009229745281920764,\n",
       "  'GS': 0.008317996343045034,\n",
       "  'INTU': 0.00763387894229239,\n",
       "  'CAT': 0.007938544890845469,\n",
       "  'QCOM': 0.007818119053361284,\n",
       "  'TXN': 0.008505957161337372,\n",
       "  'VZ': 0.012623402591086274,\n",
       "  'AXP': 0.007957853837164937,\n",
       "  'T': 0.011840235793706806,\n",
       "  'BKNG': 0.008985488578617846,\n",
       "  'SPGI': 0.008638314039381026,\n",
       "  'MS': 0.00804897416821344,\n",
       "  'RTX': 0.0109768118628871,\n",
       "  'PLTR': 0.005349194166954302,\n",
       "  'PFE': 0.011728357960394698,\n",
       "  'BLK': 0.008337167248797378,\n",
       "  'DHR': 0.009453790255577616,\n",
       "  'NEE': 0.010674799385721195,\n",
       "  'HON': 0.009638215055912905,\n",
       "  'CMCSA': 0.009789399807499124,\n",
       "  'PGR': 0.0119278551230825,\n",
       "  'LOW': 0.008493726101845522,\n",
       "  'AMGN': 0.010712885750465601,\n",
       "  'UNP': 0.009474079984108529,\n",
       "  'TJX': 0.011224203140864761,\n",
       "  'AMAT': 0.007669662255788982,\n",
       "  'UBER': 0.008179283163127818,\n",
       "  'C': 0.008377582417958105,\n",
       "  'BSX': 0.010906425732341442,\n",
       "  'ETN': 0.008148720786929697,\n",
       "  'COP': 0.011094003963302594,\n",
       "  'BA': 0.010099594522309043,\n",
       "  'BX': 0.006826719625529778,\n",
       "  'SYK': 0.00954439085652957,\n",
       "  'PANW': 0.0083212145038123,\n",
       "  'ADP': 0.009712132281191218,\n",
       "  'FI': 0.009383403392938373,\n",
       "  'ANET': 0.007476382870301635,\n",
       "  'GILD': 0.011941196223579255,\n",
       "  'BMY': 0.013944470155845714,\n",
       "  'SCHW': 0.007375236150329813,\n",
       "  'TMUS': 0.01226542937328929,\n",
       "  'DE': 0.008889034387723713,\n",
       "  'ADI': 0.008239503090396522,\n",
       "  'VRTX': 0.011053030209624405,\n",
       "  'SBUX': 0.010472007389049107,\n",
       "  'MMC': 0.011049567453329391,\n",
       "  'MDT': 0.01039975734703662,\n",
       "  'CB': 0.01175875152029368,\n",
       "  'LMT': 0.015277181432807525,\n",
       "  'KKR': 0.006940175664710733,\n",
       "  'MU': 0.008353160286620547,\n",
       "  'PLD': 0.008482340110476676,\n",
       "  'LRCX': 0.007467435691434136,\n",
       "  'EQIX': 0.008785173350105943}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPY': 0.009740158191839874,\n",
       " 'AAPL': 0.010346087478489925,\n",
       " 'NVDA': 0.007331611256518578,\n",
       " 'MSFT': 0.008856227620683397,\n",
       " 'AMZN': 0.00792905817280749,\n",
       " 'META': 0.00787432961755863,\n",
       " 'GOOGL': 0.008748186004266783,\n",
       " 'AVGO': 0.008070717284147091,\n",
       " 'TSLA': 0.01675933149726611,\n",
       " 'GOOG': 0.008677822471626108,\n",
       " 'BRK-B': 0.011095581588595306,\n",
       " 'JPM': 0.009394516800598524,\n",
       " 'LLY': 0.011772112887211469,\n",
       " 'V': 0.010978951905577674,\n",
       " 'XOM': 0.01178860069171267,\n",
       " 'UNH': 0.015145241167794418,\n",
       " 'MA': 0.010170250417754705,\n",
       " 'COST': 0.010279404852655445,\n",
       " 'PG': 0.014796765400399328,\n",
       " 'WMT': 0.01480749079389188,\n",
       " 'HD': 0.009204655389952023,\n",
       " 'NFLX': 0.007864507825361883,\n",
       " 'JNJ': 0.014190100360333562,\n",
       " 'ABBV': 0.013313933535130256,\n",
       " 'CRM': 0.008209488607251769,\n",
       " 'BAC': 0.008052784404371802,\n",
       " 'ORCL': 0.00865906917421249,\n",
       " 'MRK': 0.016279364902981135,\n",
       " 'CVX': 0.011559390697362287,\n",
       " 'KO': 0.014564853731327617,\n",
       " 'CSCO': 0.00976137566638547,\n",
       " 'WFC': 0.008470826041719759,\n",
       " 'ACN': 0.009347104164713153,\n",
       " 'NOW': 0.007732389045208798,\n",
       " 'MCD': 0.0131455387990462,\n",
       " 'PEP': 0.0148101915694524,\n",
       " 'IBM': 0.011386070898651374,\n",
       " 'DIS': 0.008883817310897183,\n",
       " 'TMO': 0.009396490799582054,\n",
       " 'LIN': 0.00970026544537352,\n",
       " 'ABT': 0.011169510861562695,\n",
       " 'AMD': 0.007017249695358713,\n",
       " 'ADBE': 0.007711373600445679,\n",
       " 'PM': 0.012872739835432655,\n",
       " 'ISRG': 0.007857243214519815,\n",
       " 'GE': 0.009179033252302507,\n",
       " 'GS': 0.00836210159279158,\n",
       " 'INTU': 0.00762575855399801,\n",
       " 'CAT': 0.007950650778080576,\n",
       " 'QCOM': 0.007757436159108727,\n",
       " 'TXN': 0.008439710567196664,\n",
       " 'VZ': 0.013063869323952749,\n",
       " 'AXP': 0.008046029775136384,\n",
       " 'T': 0.012331566367034225,\n",
       " 'BKNG': 0.009019750248088026,\n",
       " 'SPGI': 0.008613064543828267,\n",
       " 'MS': 0.008061837658312424,\n",
       " 'RTX': 0.011056280602402508,\n",
       " 'PLTR': 0.005269676199807272,\n",
       " 'PFE': 0.011623374562968762,\n",
       " 'BLK': 0.008286324030411601,\n",
       " 'DHR': 0.009458258851141906,\n",
       " 'NEE': 0.010557974579641072,\n",
       " 'HON': 0.009652228214179017,\n",
       " 'CMCSA': 0.009697590862384683,\n",
       " 'PGR': 0.011924721186198835,\n",
       " 'LOW': 0.008585964668685197,\n",
       " 'AMGN': 0.010708618528383635,\n",
       " 'UNP': 0.00931613468948795,\n",
       " 'TJX': 0.01121310600631333,\n",
       " 'AMAT': 0.007656509955908116,\n",
       " 'UBER': 0.008024607349958768,\n",
       " 'C': 0.00830661707076896,\n",
       " 'BSX': 0.011035374117170873,\n",
       " 'ETN': 0.00812636589647453,\n",
       " 'COP': 0.011198747011930287,\n",
       " 'BA': 0.010260551340146659,\n",
       " 'BX': 0.00684993010935889,\n",
       " 'SYK': 0.009425285599486322,\n",
       " 'PANW': 0.008243038815076622,\n",
       " 'ADP': 0.009751363131244044,\n",
       " 'FI': 0.009409263785445137,\n",
       " 'ANET': 0.007515942719510729,\n",
       " 'GILD': 0.01193986657006829,\n",
       " 'BMY': 0.01407258713007933,\n",
       " 'SCHW': 0.007377638075999791,\n",
       " 'TMUS': 0.0124985295117162,\n",
       " 'DE': 0.00896495283337442,\n",
       " 'ADI': 0.008135753413615495,\n",
       " 'VRTX': 0.01087558660600616,\n",
       " 'SBUX': 0.010622517241332311,\n",
       " 'MMC': 0.011072929604874986,\n",
       " 'MDT': 0.010279086510994717,\n",
       " 'CB': 0.011848576762915024,\n",
       " 'LMT': 0.014978385381678765,\n",
       " 'KKR': 0.007023144866585056,\n",
       " 'MU': 0.008260830488565336,\n",
       " 'PLD': 0.008478050453567523,\n",
       " 'LRCX': 0.007388374619486574,\n",
       " 'EQIX': 0.008855749546794531}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
